{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SISO Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to see the results you should start the MLflow ui separately**:\n",
    "1. Open a prompt/terminal and navigate to the path of this project\n",
    "2. Activate the virtual environment:  \n",
    "    (Windows: ```.venv\\eis_data_analytics\\Scripts\\activate```,  \n",
    "    Linux/Mac: ```.venv/eis_data_analytics/bin/activate```)\n",
    "3. Now start MLflow with ```mlflow server --port 1234``` consider to add e.g.: ```--workers=16 --gunicorn-opts='--timeout 600'```\n",
    "4. Open [http://127.0.0.1:1234](http://127.0.0.1:1234) in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "from modules import dataset_manipulation as dm\n",
    "from modules import eisplot as eisplot\n",
    "from modules.eisplot import plt\n",
    "from modules.eisplot import mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import hyperopt\n",
    "import mlflow\n",
    "import shapely\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "import onnxruntime as rt\n",
    "\n",
    "## if you have installed latex and want to use it for plots, uncomment the following 3 lines\n",
    "# mpl.rcParams.update({\"text.usetex\": True,'savefig.format':'pdf'})\n",
    "# mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# mpl.rc('text.latex', preamble=r'\\usepackage{underscore}')\n",
    "\n",
    "## save figures e.g. with:\n",
    "# plot_name = \"custom_3D_plot\"\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run = \"example_data\"\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run + \".parquet\"\n",
    "df = pd.read_parquet(destination_filepath)\n",
    "destination_filepath = r\"./data/key_lookup/key_lookup_\" + name_of_this_run + \".parquet\"\n",
    "key_lookup_df = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be any of the following:\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of one frequency\n",
    "# input_parameters = []\n",
    "# frequency = 0.01\n",
    "# input_parameters += [\n",
    "#     key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "#         np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "#     ]\n",
    "# ]\n",
    "# # Give it a Name (filename friendly)\n",
    "# input_parameters_name = \"Z_abs_0-01hz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of one frequency\n",
    "# input_parameters = []\n",
    "# frequency = 1\n",
    "# input_parameters += [\n",
    "#     key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "#         np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "#     ]\n",
    "# ]\n",
    "# # Give it a Name (filename friendly)\n",
    "# input_parameters_name = \"Z_abs_1hz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one frequency\n",
    "input_parameters = []\n",
    "frequency = 100\n",
    "input_parameters += [\n",
    "    key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "        np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "    ]\n",
    "]\n",
    "# Give it a Name (filename friendly)\n",
    "input_parameters_name = \"Z_abs_100hz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOC\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOH\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"Temperature\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"Temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [\"Temperature\"]\n",
    "output_intervals_for_test = {\"Temperature\": [[4, 6], [34, 36]]}\n",
    "\n",
    "# convert to training arrays\n",
    "data_set = dm.get_set(\n",
    "    df,\n",
    "    output_parameters,\n",
    "    feature_keys=input_parameters,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test,\n",
    "    label_for_test_intervals=test_labels,\n",
    "    label_name=output_parameters_name,\n",
    ")\n",
    "x_train, y_train = data_set[\"train\"]\n",
    "x_validation, y_validation = data_set[\"validation\"]\n",
    "x_test, y_test = data_set[\"test\"]\n",
    "\n",
    "# convert everything to float32\n",
    "x_train = np.float32(x_train)\n",
    "y_train = np.float32(y_train)\n",
    "x_validation = np.float32(x_validation)\n",
    "y_validation = np.float32(y_validation)\n",
    "x_test = np.float32(x_test)\n",
    "y_test = np.float32(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.use_arrhenius_correction = True\n",
    "dm.use_arrhenius_correction_with_factor = False\n",
    "dm.arrhenius_b = -15.47\n",
    "dm.arrhenius_c = 1.30\n",
    "# [dm.arrhenius_correction_inverse(dm.arrhenius_correction(i))\n",
    "#  for i in [0.01, 0.1, 1, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train = dm.arrhenius_correction(x_train)\n",
    "    x_validation = dm.arrhenius_correction(x_validation)\n",
    "    x_test = dm.arrhenius_correction(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Scaler to use (Only one!)\n",
    "dm.use_min_max_scaler = True\n",
    "dm.use_standard_scaler = False\n",
    "dm.scale_y_data = True\n",
    "# [dm.inverse_min_max_scaler(dm.min_max_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# [dm.inverse_standard_scaler(dm.standard_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "## Standard Scaler\n",
    "dm.x_mean = np.mean(x_train)\n",
    "dm.x_std = np.std(x_train)\n",
    "dm.y_mean = np.mean(y_train)\n",
    "dm.y_std = np.std(y_train)\n",
    "## Min Max scaler\n",
    "dm.x_min = np.min(x_train)\n",
    "dm.x_max = np.max(x_train)\n",
    "if dm.scale_y_data:\n",
    "    dm.y_min = np.min(y_train)\n",
    "    dm.y_max = np.max(y_train)\n",
    "else:\n",
    "    dm.y_min = np.array(0, dtype=np.float32)\n",
    "    dm.y_max = np.array(1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_min_max_scaler:\n",
    "    x_train = dm.min_max_scaler(x_train, dm.x_min, dm.x_max)\n",
    "    x_validation = dm.min_max_scaler(x_validation, dm.x_min, dm.x_max)\n",
    "    x_test = dm.min_max_scaler(x_test, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.min_max_scaler(y_train, dm.y_min, dm.y_max)\n",
    "        y_validation = dm.min_max_scaler(y_validation, dm.y_min, dm.y_max)\n",
    "        y_test = dm.min_max_scaler(y_test, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train = dm.standard_scaler(x_train, dm.x_mean, dm.x_std)\n",
    "    x_test = dm.standard_scaler(x_test, dm.x_mean, dm.x_std)\n",
    "    x_validation = dm.standard_scaler(x_validation, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.standard_scaler(y_train, dm.y_mean, dm.y_std)\n",
    "        y_validation = dm.standard_scaler(y_validation, dm.y_mean, dm.y_std)\n",
    "        y_test = dm.standard_scaler(y_test, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is logged in mlflow, create a new experiment\n",
    "experiment_name = (\n",
    "    name_of_this_run\n",
    "    + \"_\"\n",
    "    + \"SISO_ElasticNet_\"\n",
    "    + input_parameters_name\n",
    "    + \"_\"\n",
    "    + output_parameters_name\n",
    ")\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective to be minimized\n",
    "\n",
    "\n",
    "def objective(params, experiment_id):\n",
    "    default_params = {\n",
    "        \"log_model\": False,\n",
    "        \"plot_fit\": False,\n",
    "        \"plot_diag\": False,\n",
    "        \"log_plot_type\": \"png\",\n",
    "        \"alpha\": 1.0,\n",
    "        \"l1_ratio\": 0.5,\n",
    "        \"tol\": 0.0001,\n",
    "        \"selection\": \"random\",\n",
    "        \"use_arrhenius_correction\": dm.use_arrhenius_correction,\n",
    "        \"use_arrhenius_correction_with_factor\": dm.use_arrhenius_correction_with_factor,\n",
    "        \"use_min_max_scaler\": dm.use_min_max_scaler,\n",
    "        \"use_standard_scaler\": dm.use_standard_scaler,\n",
    "        \"use_scale_y_data\": dm.scale_y_data,\n",
    "        \"x_mean\": dm.x_mean,\n",
    "        \"x_std\": dm.x_std,\n",
    "        \"y_mean\": dm.y_mean,\n",
    "        \"y_std\": dm.y_std,\n",
    "        \"x_min\": dm.x_min,\n",
    "        \"x_max\": dm.x_max,\n",
    "        \"y_min\": dm.y_min,\n",
    "        \"y_max\": dm.y_max,\n",
    "    }\n",
    "\n",
    "    default_params.update(params)\n",
    "    merged_params = default_params\n",
    "    dm.use_arrhenius_correction = merged_params[\"use_arrhenius_correction\"]\n",
    "    dm.use_arrhenius_correction_with_factor = merged_params[\"use_arrhenius_correction_with_factor\"]\n",
    "    dm.use_min_max_scaler = merged_params[\"use_min_max_scaler\"]\n",
    "    dm.use_standard_scaler = merged_params[\"use_standard_scaler\"]\n",
    "    dm.scale_y_data = merged_params[\"use_scale_y_data\"]\n",
    "    dm.x_mean = merged_params[\"x_mean\"]\n",
    "    dm.x_std = merged_params[\"x_std\"]\n",
    "    dm.y_mean = merged_params[\"y_mean\"]\n",
    "    dm.y_std = merged_params[\"y_std\"]\n",
    "    dm.x_min = merged_params[\"x_min\"]\n",
    "    dm.x_max = merged_params[\"x_max\"]\n",
    "    dm.y_min = merged_params[\"y_min\"]\n",
    "    dm.y_max = merged_params[\"y_max\"]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"ElasticNet\"):\n",
    "        if merged_params[\"log_model\"]:\n",
    "            mlflow.sklearn.autolog()\n",
    "\n",
    "        mlflow.log_param(\"alpha\", merged_params[\"alpha\"])\n",
    "        mlflow.log_param(\"l1_ratio\", merged_params[\"l1_ratio\"])\n",
    "        mlflow.log_param(\"tol\", merged_params[\"tol\"])\n",
    "        mlflow.log_param(\"selection\", merged_params[\"selection\"])\n",
    "        mlflow.log_param(\"arrhenius_correction\", dm.use_arrhenius_correction)\n",
    "        mlflow.log_param(\n",
    "            \"arrhenius_correction_with_factor\", dm.use_arrhenius_correction_with_factor\n",
    "        )\n",
    "        mlflow.log_param(\"min_max_scaler\", dm.use_min_max_scaler)\n",
    "        mlflow.log_param(\"standard_scaler\", dm.use_standard_scaler)\n",
    "        mlflow.log_param(\"scale_y_data\", dm.scale_y_data)\n",
    "\n",
    "        model = ElasticNet(\n",
    "            alpha=merged_params[\"alpha\"],\n",
    "            l1_ratio=merged_params[\"l1_ratio\"],\n",
    "            selection=merged_params[\"selection\"],\n",
    "            tol=merged_params[\"tol\"],\n",
    "            max_iter=100000,\n",
    "        )\n",
    "\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        model.score(x_validation, y_validation.ravel())\n",
    "\n",
    "        train_maxae_temp = dm.evaluate_max_abs_error(model, x_train, y_train)\n",
    "        validation_maxae_temp = dm.evaluate_max_abs_error(\n",
    "            model, x_validation, y_validation\n",
    "        )\n",
    "        test_maxae_temp = dm.evaluate_max_abs_error(model, x_test, y_test)\n",
    "        train_mse_temp = dm.evaluate_mse(model, x_train, y_train)\n",
    "        validation_mse_temp = dm.evaluate_mse(model, x_validation, y_validation)\n",
    "        test_mse_temp = dm.evaluate_mse(model, x_test, y_test)\n",
    "        train_rmse_temp = dm.evaluate_rmse(model, x_train, y_train)\n",
    "        validation_rmse_temp = dm.evaluate_rmse(model, x_validation, y_validation)\n",
    "        test_rmse_temp = dm.evaluate_rmse(model, x_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"train_maxae_temp\", train_maxae_temp)\n",
    "        mlflow.log_metric(\"validation_maxae_temp\", validation_maxae_temp)\n",
    "        mlflow.log_metric(\"test_maxae_temp\", test_maxae_temp)\n",
    "        mlflow.log_metric(\"train_mse_temp\", train_mse_temp)\n",
    "        mlflow.log_metric(\"validation_mse_temp\", validation_mse_temp)\n",
    "        mlflow.log_metric(\"test_mse_temp\", test_mse_temp)\n",
    "        mlflow.log_metric(\"train_rmse_temp\", train_rmse_temp)\n",
    "        mlflow.log_metric(\"validation_rmse_temp\", validation_rmse_temp)\n",
    "        mlflow.log_metric(\"test_rmse_temp\", test_rmse_temp)\n",
    "\n",
    "        if merged_params[\"plot_diag\"]:\n",
    "            dm.plot_diag_during_fitting(\n",
    "                model,\n",
    "                name_of_this_run,\n",
    "                output_parameters,\n",
    "                x_test,\n",
    "                x_train,\n",
    "                x_validation,\n",
    "                data_set,\n",
    "                train_rmse_temp,\n",
    "                validation_rmse_temp,\n",
    "                test_rmse_temp,\n",
    "                merged_params,\n",
    "            )\n",
    "\n",
    "        if merged_params[\"plot_fit\"]:\n",
    "            dm.plot_fit_during_fitting(\n",
    "                model,\n",
    "                name_of_this_run,\n",
    "                input_parameters,\n",
    "                output_parameters,\n",
    "                x_train,\n",
    "                x_validation,\n",
    "                x_test,\n",
    "                y_train,\n",
    "                y_validation,\n",
    "                y_test,\n",
    "                train_rmse_temp,\n",
    "                validation_rmse_temp,\n",
    "                test_rmse_temp,\n",
    "                merged_params,\n",
    "            )\n",
    "\n",
    "        mlflow.log_metric(\n",
    "            \"std_rmse\", np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"max_rmse\", np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"std_times_max_rmse\",\n",
    "            np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "            * np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp]),\n",
    "        )\n",
    "\n",
    "        # fmin() minimizes the objective\n",
    "        weighted_fit_result = np.max(\n",
    "            [train_rmse_temp, validation_rmse_temp, test_rmse_temp]\n",
    "        )\n",
    "\n",
    "        mlflow.log_metric(\"weighted_fit_result\", weighted_fit_result)\n",
    "\n",
    "    return {\"loss\": weighted_fit_result, \"status\": hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the search space\n",
    "\n",
    "search_space = hyperopt.hp.choice(\n",
    "    \"ElasticNet\",\n",
    "    [\n",
    "        {\n",
    "            \"log_model\": hyperopt.hp.choice(\"log_model\", [True]),\n",
    "            \"plot_fit\": hyperopt.hp.choice(\"plot_fit\", [True]),\n",
    "            \"plot_diag\": hyperopt.hp.choice(\"plot_diag\", [True]),\n",
    "            \"log_plot_type\": hyperopt.hp.choice(\"log_plot_type\", [\"svg\"]),\n",
    "            \"tol\": hyperopt.hp.loguniform(\"tol\", np.log(0.000001), np.log(0.01)),\n",
    "            \"alpha\": hyperopt.hp.uniform(\"alpha\", 0, 2),\n",
    "            \"l1_ratio\": hyperopt.hp.uniform(\"l1_ratio\", 0.01, 1),\n",
    "            \"selection\": hyperopt.hp.choice(\"selection\", [\"random\"]),\n",
    "            \"use_arrhenius_correction\": hyperopt.hp.choice(\"use_arrhenius_correction\", [dm.use_arrhenius_correction]),\n",
    "            \"use_arrhenius_correction_with_factor\": hyperopt.hp.choice(\"use_arrhenius_correction_with_factor\", [dm.use_arrhenius_correction_with_factor]),\n",
    "            \"use_min_max_scaler\": hyperopt.hp.choice(\"use_min_max_scaler\", [dm.use_min_max_scaler]),\n",
    "            \"use_standard_scaler\": hyperopt.hp.choice(\"use_standard_scaler\", [dm.use_standard_scaler]),\n",
    "            \"use_scale_y_data\": hyperopt.hp.choice(\"use_scale_y_data\", [dm.scale_y_data]),\n",
    "            \"x_mean\": hyperopt.hp.choice(\"x_mean\", [dm.x_mean]),\n",
    "            \"x_std\": hyperopt.hp.choice(\"x_std\", [dm.x_std]),\n",
    "            \"y_mean\": hyperopt.hp.choice(\"y_mean\", [dm.y_mean]),\n",
    "            \"y_std\": hyperopt.hp.choice(\"y_std\", [dm.y_std]),\n",
    "            \"x_min\": hyperopt.hp.choice(\"x_min\", [dm.x_min]),\n",
    "            \"x_max\": hyperopt.hp.choice(\"x_max\", [dm.x_max]),\n",
    "            \"y_min\": hyperopt.hp.choice(\"y_min\", [dm.y_min]),\n",
    "            \"y_max\": hyperopt.hp.choice(\"y_max\", [dm.y_max]),\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Choose an optimization type\n",
    "\n",
    "# algo=hyperopt.tpe.suggest\n",
    "algo = hyperopt.rand.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model, you can track it in mlflow: [http://127.0.0.1:1234](http://127.0.0.1:1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timout_in_minutes = 24 * 60\n",
    "max_evals = 10\n",
    "\n",
    "# if java is installed (only recommended under linux or wsl)\n",
    "# import pyspark\n",
    "# spark_trails = hyperopt.SparkTrials(parallelism=16)\n",
    "# best_result = hyperopt.fmin(\n",
    "#     fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "#     space=search_space,\n",
    "#     algo=algo,\n",
    "#     max_evals=max_evals,\n",
    "#     timeout=timout_in_minutes * 60,\n",
    "#     trials=spark_trails,\n",
    "# )\n",
    "# if java is not available\n",
    "best_result = hyperopt.fmin(\n",
    "    fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=max_evals,\n",
    "    timeout=timout_in_minutes * 60,\n",
    ")\n",
    "\n",
    "print(hyperopt.space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best Model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run_eval = name_of_this_run\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run_eval + \".parquet\"\n",
    "df_eval = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if needed\n",
    "input_parameters_eval = input_parameters\n",
    "input_parameters_name_eval = input_parameters_name\n",
    "output_parameters_eval = output_parameters\n",
    "output_parameters_name_eval = output_parameters_name\n",
    "\n",
    "test_labels_eval = test_labels\n",
    "output_intervals_for_test_eval = output_intervals_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_eval = dm.get_set(\n",
    "    df_eval,\n",
    "    output_parameters_eval,\n",
    "    feature_keys=input_parameters_eval,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test_eval,\n",
    "    label_for_test_intervals=test_labels_eval,\n",
    "    label_name=output_parameters_name_eval,\n",
    ")\n",
    "x_train_eval, y_train_eval = data_set_eval[\"train\"]\n",
    "x_validation_eval, y_validation_eval = data_set_eval[\"validation\"]\n",
    "x_test_eval, y_test_eval = data_set_eval[\"test\"]\n",
    "\n",
    "x_train_eval = np.float32(x_train_eval)\n",
    "y_train_eval = np.float32(y_train_eval)\n",
    "x_validation_eval = np.float32(x_validation_eval)\n",
    "y_validation_eval = np.float32(y_validation_eval)\n",
    "x_test_eval = np.float32(x_test_eval)\n",
    "y_test_eval = np.float32(y_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train_eval = dm.arrhenius_correction(x_train_eval)\n",
    "    x_validation_eval = dm.arrhenius_correction(x_validation_eval)\n",
    "    x_test_eval = dm.arrhenius_correction(x_test_eval)\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_train_eval = dm.min_max_scaler(x_train_eval, dm.x_min, dm.x_max)\n",
    "    x_validation_eval = dm.min_max_scaler(x_validation_eval, dm.x_min, dm.x_max)\n",
    "    x_test_eval = dm.min_max_scaler(x_test_eval, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_eval = dm.min_max_scaler(y_validation_eval, dm.y_min, dm.y_max)\n",
    "        y_test_eval = dm.min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train_eval = dm.standard_scaler(x_train_eval, dm.x_mean, dm.x_std)\n",
    "    x_test_eval = dm.standard_scaler(x_test_eval, dm.x_mean, dm.x_std)\n",
    "    x_validation_eval = dm.standard_scaler(x_validation_eval, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_eval = dm.standard_scaler(y_validation_eval, dm.y_mean, dm.y_std)\n",
    "        y_test_eval = dm.standard_scaler(y_test_eval, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [http://127.0.0.1:1234](http://127.0.0.1:1234) to select a fitted model. If you click on it, you can extract the run ID. It could look like this: \"ad26474e8c324f84906c9fc501928cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose a specific model\n",
    "# logged_model = 'ad26474e8c324f84906c9fc501928cae'\n",
    "# or just load the best model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "    order_by=[\"metrics.max_rmse\"],\n",
    "    max_results=1,\n",
    ")\n",
    "logged_model = runs[0].info.run_id\n",
    "\n",
    "# Load model as a Sklearn.\n",
    "run_eval = mlflow.get_run(logged_model)\n",
    "loaded_model = mlflow.sklearn.load_model(run_eval.info.artifact_uri + \"/model/\")\n",
    "\n",
    "train_rmse_temp = dm.evaluate_rmse(loaded_model, x_train_eval, y_train_eval)\n",
    "print(\"Train RMSE: \" + str(train_rmse_temp))\n",
    "validation_rmse_temp = dm.evaluate_rmse(\n",
    "    loaded_model, x_validation_eval, y_validation_eval\n",
    ")\n",
    "print(\"Validation RMSE: \" + str(validation_rmse_temp))\n",
    "test_rmse_temp = dm.evaluate_rmse(loaded_model, x_test_eval, y_test_eval)\n",
    "print(\"Test RMSE: \" + str(test_rmse_temp))\n",
    "\n",
    "print(\n",
    "    f\"y = {loaded_model.intercept_:.3f} + \"\n",
    "    + \" + \".join(\n",
    "        [\n",
    "            f\"{coef:.3f}*x^{i+1}\"\n",
    "            for i, coef in enumerate(loaded_model.coef_)\n",
    "            if coef != 0\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "unique_model_name = (\n",
    "    experiment_name\n",
    "    + \"_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \"_\"\n",
    "    + logged_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "cell_list_train = list(set(data_set_eval[\"df_train\"].index.get_level_values(0)))\n",
    "y_pred_train_eval = loaded_model.predict(x_train_eval)\n",
    "y_pred_train_eval = y_pred_train_eval.ravel()\n",
    "\n",
    "cell_list_validation = list(\n",
    "    set(data_set_eval[\"df_validation\"].index.get_level_values(0))\n",
    ")\n",
    "y_pred_validation_eval = loaded_model.predict(x_validation_eval)\n",
    "y_pred_validation_eval = y_pred_validation_eval.ravel()\n",
    "\n",
    "cell_list_test = list(set(data_set_eval[\"df_test\"].index.get_level_values(0)))\n",
    "y_pred_test_eval = loaded_model.predict(x_test_eval)\n",
    "y_pred_test_eval = y_pred_test_eval.ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        y_pred_train_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_train_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_test_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_train_plot = dm.inverse_min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_plot = dm.inverse_min_max_scaler(\n",
    "            y_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_test_plot = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        y_pred_train_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_train_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_test_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_train_plot = dm.inverse_standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_plot = dm.inverse_standard_scaler(\n",
    "            y_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_test_plot = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_train_plot = y_train_eval\n",
    "    y_validation_plot = y_validation_eval\n",
    "    y_test_plot = y_test_eval\n",
    "\n",
    "fig, ax = eisplot.setup_scatter(\n",
    "    data_set,\n",
    "    test_rmse_temp,\n",
    "    title=False,\n",
    "    legend=False,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    ax_xlabel=False,\n",
    "    ax_ylabel=False,\n",
    "    subplots_adjust=True,\n",
    "    add_trendline=True,\n",
    "    label=\"\",\n",
    ")\n",
    "ax.plot(\n",
    "    y_train_plot,\n",
    "    y_pred_train_eval,\n",
    "    \".\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_validation_plot,\n",
    "    y_pred_validation_eval,\n",
    "    \"1\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_test_plot,\n",
    "    y_pred_test_eval,\n",
    "    \"2\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"actual: Output\")\n",
    "ax.set_ylabel(\"predicted: Output\")\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0], [0], color=eisplot.rwth_colors.colors[(\"green\", 100)], label=\"ideal\"\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\".\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"1\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"2\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_min_plot = dm.inverse_min_max_scaler(\n",
    "        np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_min,\n",
    "        dm.x_max,\n",
    "    )\n",
    "    x_max_plot = dm.inverse_min_max_scaler(\n",
    "        np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_min,\n",
    "        dm.x_max,\n",
    "    )\n",
    "elif dm.use_standard_scaler:\n",
    "    x_min_plot = dm.inverse_standard_scaler(\n",
    "        np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_mean,\n",
    "        dm.x_std,\n",
    "    )\n",
    "    x_max_plot = dm.inverse_standard_scaler(\n",
    "        np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_mean,\n",
    "        dm.x_std,\n",
    "    )\n",
    "else:\n",
    "    x_min_plot = np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval)))\n",
    "    x_max_plot = np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval)))\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_tmp = x_min_plot\n",
    "    x_min_plot = dm.arrhenius_correction_inverse(x_max_plot)\n",
    "    x_max_plot = dm.arrhenius_correction_inverse(x_tmp)\n",
    "\n",
    "x_min_plot = x_min_plot * 0.8\n",
    "x_max_plot = x_max_plot * 1.2\n",
    "\n",
    "x_plot = np.linspace(x_min_plot, x_max_plot, 1000, dtype=np.float32)[:, None]\n",
    "\n",
    "x_plot_arrhenius = x_plot\n",
    "x_train_arrhenius = x_train_eval\n",
    "x_validation_arrhenius = x_validation_eval\n",
    "x_test_arrhenius = x_test_eval\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_plot = dm.arrhenius_correction(x_plot)\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_plot = dm.min_max_scaler(x_plot, dm.x_min, dm.x_max)\n",
    "    x_train_arrhenius = dm.inverse_min_max_scaler(x_train_arrhenius, dm.x_min, dm.x_max)\n",
    "    x_validation_arrhenius = dm.inverse_min_max_scaler(\n",
    "        x_validation_arrhenius, dm.x_min, dm.x_max\n",
    "    )\n",
    "    x_test_arrhenius = dm.inverse_min_max_scaler(x_test_arrhenius, dm.x_min, dm.x_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_plot = dm.standard_scaler(x_plot, dm.x_mean, dm.x_std)\n",
    "    x_train_arrhenius = dm.inverse_standard_scaler(\n",
    "        x_train_arrhenius, dm.x_mean, dm.x_std\n",
    "    )\n",
    "    x_validation_arrhenius = dm.inverse_standard_scaler(\n",
    "        x_validation_arrhenius, dm.x_mean, dm.x_std\n",
    "    )\n",
    "    x_test_arrhenius = dm.inverse_standard_scaler(x_test_arrhenius, dm.x_mean, dm.x_std)\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_train_arrhenius = dm.arrhenius_correction_inverse(x_train_arrhenius)\n",
    "    x_validation_arrhenius = dm.arrhenius_correction_inverse(x_validation_arrhenius)\n",
    "    x_test_arrhenius = dm.arrhenius_correction_inverse(x_test_arrhenius)\n",
    "\n",
    "y_svr = loaded_model.predict(x_plot)\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        y_svr = dm.inverse_min_max_scaler(y_svr, dm.y_min, dm.y_max)\n",
    "        y_train_plot = dm.inverse_min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_plot = dm.inverse_min_max_scaler(\n",
    "            y_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_test_plot = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        y_svr = dm.inverse_standard_scaler(y_svr, dm.y_mean, dm.y_std)\n",
    "        y_train_plot = dm.inverse_standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_plot = dm.inverse_standard_scaler(\n",
    "            y_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_test_plot = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "\n",
    "ax.plot(\n",
    "    x_plot_arrhenius,\n",
    "    y_svr,\n",
    "    lw=2,\n",
    "    label=\"Regression\",\n",
    "    color=eisplot.rwth_colors.colors[(\"bordeaux\", 100)],\n",
    ")\n",
    "ax.scatter(\n",
    "    x_train_arrhenius,\n",
    "    y_train_plot,\n",
    "    marker=\".\",\n",
    "    label=\"train\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    x_validation_arrhenius,\n",
    "    y_validation_plot,\n",
    "    marker=\"1\",\n",
    "    label=\"validation\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    x_test_arrhenius,\n",
    "    y_test_plot,\n",
    "    marker=\"2\",\n",
    "    label=\"test\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Output Value\")\n",
    "ax.set_xlabel(\"Input Value\")\n",
    "ax.grid()\n",
    "\n",
    "ax.legend(loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert, Export, Test and Validate with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_elasticnet(scope, operator, container):\n",
    "    from skl2onnx.proto import onnx_proto\n",
    "    from skl2onnx.common._apply_operation import apply_add, apply_matmul\n",
    "\n",
    "    op = operator.raw_operator\n",
    "\n",
    "    coef = op.coef_.astype(float).reshape(-1, 1)\n",
    "    intercept = op.intercept_.astype(float).reshape(1)\n",
    "\n",
    "    coef_name = scope.get_unique_variable_name(\"coef\")\n",
    "    intercept_name = scope.get_unique_variable_name(\"intercept\")\n",
    "\n",
    "    container.add_initializer(\n",
    "        coef_name, onnx_proto.TensorProto.FLOAT, coef.shape, coef.flatten()\n",
    "    )\n",
    "    container.add_initializer(\n",
    "        intercept_name, onnx_proto.TensorProto.FLOAT, intercept.shape, intercept\n",
    "    )\n",
    "\n",
    "    matmul_output_name = scope.get_unique_variable_name(\"matmul_output\")\n",
    "    apply_matmul(\n",
    "        scope, [operator.inputs[0].full_name, coef_name], matmul_output_name, container\n",
    "    )\n",
    "    apply_add(\n",
    "        scope,\n",
    "        [matmul_output_name, intercept_name],\n",
    "        operator.outputs[0].full_name,\n",
    "        container,\n",
    "    )\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    ElasticNet,\n",
    "    \"SklearnElasticNet\",\n",
    "    calculate_linear_regressor_output_shapes,\n",
    "    convert_elasticnet,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = [(\"float_input\", FloatTensorType([None, len(x_train[0])]))]\n",
    "onnx_filename = \"microcontroller_eis_network/onnx_export/\" + unique_model_name + \".onnx\"\n",
    "onx = convert_sklearn(loaded_model, initial_types=input_type)\n",
    "with open(onnx_filename, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_filename, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval})[0]\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "        y_test_eval_ref = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "        y_test_eval_ref = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_test_eval_ref = y_test_eval.copy()\n",
    "\n",
    "diff = pred_onx.ravel() - y_test_eval_ref.ravel()\n",
    "print(np.max(np.abs(diff)))\n",
    "print(np.mean(diff))\n",
    "print(np.std(diff))\n",
    "print(np.sqrt(np.mean((diff) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_eval_float32 = x_test_eval.astype(np.float32)\n",
    "\n",
    "pred_sklearn = loaded_model.predict(x_test_eval_float32)\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval_float32})[0].ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_sklearn = dm.inverse_min_max_scaler(pred_sklearn, dm.y_min, dm.y_max)\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_sklearn = dm.inverse_standard_scaler(pred_sklearn, dm.y_mean, dm.y_std)\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "\n",
    "diff = pred_sklearn.ravel() - pred_onx.ravel()\n",
    "print(\"Max difference between scikit-learn and ONNX predictions:\", np.max(np.abs(diff)))\n",
    "print(\"Mean difference between scikit-learn and ONNX predictions:\", np.mean(diff))\n",
    "print(\"RMSE of differences:\", np.sqrt(np.mean(diff**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the test data for the microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_path = \"microcontroller_eis_network/Core/Inc/\"\n",
    "dm.create_test_header_file(data_set_eval, header_path, unique_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further comparison of different fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()\n",
    "experiment_id = mlflow_exp.experiment_id\n",
    "experiment_id\n",
    "\n",
    "for exp in mlflow.search_experiments():\n",
    "    if exp.experiment_id == experiment_id:\n",
    "        experiment_tmp = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "        experiment_list = pd.concat([experiment_list, experiment_tmp])\n",
    "\n",
    "experiment_list = experiment_list.reset_index(drop=True)\n",
    "experiment_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_values = [\n",
    "    experiment_list[\"metrics.train_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.test_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.train_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.train_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_rmse_temp\"].values,\n",
    "    experiment_list[\"params.alpha\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.l1_ratio\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.tol\"].values.astype(np.float64),\n",
    "]\n",
    "df_experiment = pd.DataFrame(\n",
    "    np.transpose(scatter_values),\n",
    "    columns=[\n",
    "        \"Train MAXAE in K\",\n",
    "        \"Validation MAXAE in K\",\n",
    "        \"Test MAXAE in K\",\n",
    "        \"Train MSE in K^2\",\n",
    "        \"Validation MSE in K^2\",\n",
    "        \"Test MSE in K^2\",\n",
    "        \"Train RMSE in K\",\n",
    "        \"Validation RMSE in K\",\n",
    "        \"Test RMSE in K\",\n",
    "        \"Alpha\",\n",
    "        \"L1 Ratio\",\n",
    "        \"Tolerance\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the error if necessary\n",
    "df_experiment[df_experiment[\"Test RMSE in K\"] > 100] = np.nan\n",
    "df_experiment = df_experiment.dropna(subset=[\"Test RMSE in K\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_experiment.corr()\n",
    "corr.style.background_gradient(cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(unique_model_name)\n",
    "except:\n",
    "    unique_model_name = (\n",
    "        experiment_name\n",
    "        + \"_\"\n",
    "        + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filepath = r\"./mlruns/\" + unique_model_name + \".parquet\"\n",
    "experiment_list.to_parquet(destination_filepath, compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12 * eisplot.cm, 12 * eisplot.cm), sharex=True)\n",
    "\n",
    "variables = [\"\", \"Alpha\", \"L1 Ratio\", \"Tolerance\"]\n",
    "\n",
    "for variable_idx, variable in enumerate(variables):\n",
    "    if variable_idx == 0:\n",
    "        continue\n",
    "    plot_column = np.floor(variable_idx / 2).astype(\"int\")\n",
    "    plot_row = variable_idx - 2 * plot_column\n",
    "\n",
    "    concave_hull_ratio = 0.25\n",
    "\n",
    "    min_error = np.min(\n",
    "        [\n",
    "            df_experiment[\"Train RMSE in K\"].values,\n",
    "            df_experiment[\"Validation RMSE in K\"].values,\n",
    "            df_experiment[\"Test RMSE in K\"].values,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Train RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Train RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Validation RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Validation RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Test RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Test RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    axs[plot_column, plot_row].set_ylabel(variable)\n",
    "    axs[plot_column, plot_row].set_xscale(\"log\")\n",
    "    axs[plot_column, plot_row].grid()\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\":\",\n",
    "        color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    "        label=\"selected value\",\n",
    "        alpha=1.0,\n",
    "    ),\n",
    "]\n",
    "fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper center\",\n",
    "    scatterpoints=1,\n",
    "    ncol=4,\n",
    ")\n",
    "\n",
    "\n",
    "axs[1, 0].set_xlabel(\"RMSE in K\")\n",
    "axs[1, 1].set_xlabel(\"RMSE in K\")\n",
    "fig.tight_layout()\n",
    "\n",
    "x_values = np.array(axs[0, 0].get_xlim()) * 0.95\n",
    "\n",
    "axs[0, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"alpha\"]), float(run_eval.data.params[\"alpha\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"l1_ratio\"]), float(run_eval.data.params[\"l1_ratio\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"tol\"]), float(run_eval.data.params[\"tol\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "\n",
    "axs[1, 1].set_yscale(\"log\")\n",
    "\n",
    "axs[0, 0].remove()\n",
    "\n",
    "fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
