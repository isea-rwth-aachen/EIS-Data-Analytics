{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SISO Support Vector Classification (SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to see the results you should start the MLflow ui separately**:\n",
    "1. Open a prompt/terminal and navigate to the path of this project\n",
    "2. Activate the virtual environment:  \n",
    "    (Windows: ```.venv\\eis_data_analytics\\Scripts\\activate```,  \n",
    "    Linux/Mac: ```.venv/eis_data_analytics/bin/activate```)\n",
    "3. Now start MLflow with ```mlflow server --port 1234``` consider to add e.g.: ```--workers=16 --gunicorn-opts='--timeout 600'```\n",
    "4. Open [http://127.0.0.1:1234](http://127.0.0.1:1234) in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "from modules import dataset_manipulation as dm\n",
    "from modules import eisplot as eisplot\n",
    "from modules.eisplot import plt\n",
    "from modules.eisplot import mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import hyperopt\n",
    "import mlflow\n",
    "import shapely\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from modules.eisplot import sns\n",
    "\n",
    "## if you have installed latex and want to use it for plots, uncomment the following 3 lines\n",
    "# mpl.rcParams.update({\"text.usetex\": True,'savefig.format':'pdf'})\n",
    "# mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# mpl.rc('text.latex', preamble=r'\\usepackage{underscore}')\n",
    "\n",
    "## save figures e.g. with:\n",
    "# plot_name = \"custom_3D_plot\"\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run = \"example_data\"\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run + \".parquet\"\n",
    "df = pd.read_parquet(destination_filepath)\n",
    "destination_filepath = r\"./data/key_lookup/key_lookup_\" + name_of_this_run + \".parquet\"\n",
    "key_lookup_df = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be any of the following:\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of one frequency\n",
    "# input_parameters = []\n",
    "# frequency = 0.01\n",
    "# input_parameters += [\n",
    "#     key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "#         np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "#     ]\n",
    "# ]\n",
    "# # Give it a Name (filename friendly)\n",
    "# input_parameters_name = \"Z_abs_0-01hz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of one frequency\n",
    "# input_parameters = []\n",
    "# frequency = 1\n",
    "# input_parameters += [\n",
    "#     key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "#         np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "#     ]\n",
    "# ]\n",
    "# # Give it a Name (filename friendly)\n",
    "# input_parameters_name = \"Z_abs_1hz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of one frequency\n",
    "input_parameters = []\n",
    "frequency = 100\n",
    "input_parameters += [\n",
    "    key_lookup_df[\"EIS_Z_abs\"].loc[\n",
    "        np.argmin(np.abs(key_lookup_df[\"frequency\"].values - frequency))\n",
    "    ]\n",
    "]\n",
    "# Give it a Name (filename friendly)\n",
    "input_parameters_name = \"Z_abs_100hz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOC\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOH\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"Temperature\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"Temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [\"Temperature\"]\n",
    "\n",
    "# convert to training arrays\n",
    "data_set = dm.get_set(\n",
    "    df,\n",
    "    output_parameters,\n",
    "    feature_keys=input_parameters,\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1,\n",
    "    label_for_test_intervals=test_labels,\n",
    "    label_name=output_parameters_name,\n",
    ")\n",
    "x_train, y_train = data_set[\"train\"]\n",
    "x_validation, y_validation = data_set[\"validation\"]\n",
    "x_test, y_test = data_set[\"test\"]\n",
    "\n",
    "# convert everything to float32\n",
    "x_train = np.float32(x_train)\n",
    "y_train = np.float32(y_train)\n",
    "x_validation = np.float32(x_validation)\n",
    "y_validation = np.float32(y_validation)\n",
    "x_test = np.float32(x_test)\n",
    "y_test = np.float32(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.use_arrhenius_correction = True\n",
    "dm.use_arrhenius_correction_with_factor = False\n",
    "dm.arrhenius_b = -15.47\n",
    "dm.arrhenius_c = 1.30\n",
    "# [dm.arrhenius_correction_inverse(dm.arrhenius_correction(i))\n",
    "#  for i in [0.01, 0.1, 1, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train = dm.arrhenius_correction(x_train)\n",
    "    x_validation = dm.arrhenius_correction(x_validation)\n",
    "    x_test = dm.arrhenius_correction(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Scaler to use (Only one!)\n",
    "dm.use_min_max_scaler = True\n",
    "dm.use_standard_scaler = False\n",
    "dm.scale_y_data = False  # not supported for SVC\n",
    "# [dm.inverse_min_max_scaler(dm.min_max_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# [dm.inverse_standard_scaler(dm.standard_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# Standard Scaler\n",
    "dm.x_mean = np.mean(x_train)\n",
    "dm.x_std = np.std(x_train)\n",
    "dm.y_mean = np.mean(y_train)\n",
    "dm.y_std = np.std(y_train)\n",
    "# Min Max scaler\n",
    "dm.x_min = np.min(x_train)\n",
    "dm.x_max = np.max(x_train)\n",
    "\n",
    "dm.y_min = np.array(0, dtype=np.float32)\n",
    "dm.y_max = np.array(1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_min_max_scaler:\n",
    "    x_train = dm.min_max_scaler(x_train, dm.x_min, dm.x_max)\n",
    "    x_validation = dm.min_max_scaler(x_validation, dm.x_min, dm.x_max)\n",
    "    x_test = dm.min_max_scaler(x_test, dm.x_min, dm.x_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train = dm.standard_scaler(x_train, dm.x_mean, dm.x_std)\n",
    "    x_test = dm.standard_scaler(x_test, dm.x_mean, dm.x_std)\n",
    "    x_validation = dm.standard_scaler(x_validation, dm.x_mean, dm.x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Classes, e.g. by quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_parameters_name == \"Temperature\":\n",
    "    discretize_minimum = -25\n",
    "    discretize_delta = 5\n",
    "elif output_parameters_name == \"SOC\":\n",
    "    discretize_minimum = 0\n",
    "    discretize_delta = 5\n",
    "elif output_parameters_name == \"SOH\":\n",
    "    discretize_minimum = 0\n",
    "    discretize_delta = 5\n",
    "\n",
    "y_train = dm.quantize_data(y_train, discretize_minimum, discretize_delta)\n",
    "y_validation = dm.quantize_data(y_validation, discretize_minimum, discretize_delta)\n",
    "y_test = dm.quantize_data(y_test, discretize_minimum, discretize_delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is logged in mlflow, create a new experiment\n",
    "experiment_name = (\n",
    "    name_of_this_run\n",
    "    + \"_\"\n",
    "    + \"SISO_SVC_\"\n",
    "    + input_parameters_name\n",
    "    + \"_\"\n",
    "    + output_parameters_name\n",
    ")\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective to be minimized\n",
    "\n",
    "\n",
    "def objective(params, experiment_id):\n",
    "    default_params = {\n",
    "        \"log_model\": False,\n",
    "        \"plot_fit\": False,\n",
    "        \"plot_diag\": False,\n",
    "        \"log_plot_type\": \"png\",\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"C\": 1,\n",
    "        \"tol\": 0.001,\n",
    "        \"coef0\": 0.0,\n",
    "        \"gamma\": \"auto\",\n",
    "        \"degree\": 3,\n",
    "        \"use_arrhenius_correction\": dm.use_arrhenius_correction,\n",
    "        \"use_arrhenius_correction_with_factor\": dm.use_arrhenius_correction_with_factor,\n",
    "        \"use_min_max_scaler\": dm.use_min_max_scaler,\n",
    "        \"use_standard_scaler\": dm.use_standard_scaler,\n",
    "        \"use_scale_y_data\": dm.scale_y_data,\n",
    "        \"x_mean\": dm.x_mean,\n",
    "        \"x_std\": dm.x_std,\n",
    "        \"y_mean\": dm.y_mean,\n",
    "        \"y_std\": dm.y_std,\n",
    "        \"x_min\": dm.x_min,\n",
    "        \"x_max\": dm.x_max,\n",
    "        \"y_min\": dm.y_min,\n",
    "        \"y_max\": dm.y_max,\n",
    "    }\n",
    "\n",
    "    default_params.update(params)\n",
    "    merged_params = default_params\n",
    "    dm.use_arrhenius_correction = merged_params[\"use_arrhenius_correction\"]\n",
    "    dm.use_arrhenius_correction_with_factor = merged_params[\n",
    "        \"use_arrhenius_correction_with_factor\"\n",
    "    ]\n",
    "    dm.use_min_max_scaler = merged_params[\"use_min_max_scaler\"]\n",
    "    dm.use_standard_scaler = merged_params[\"use_standard_scaler\"]\n",
    "    dm.scale_y_data = merged_params[\"use_scale_y_data\"]\n",
    "    dm.x_mean = merged_params[\"x_mean\"]\n",
    "    dm.x_std = merged_params[\"x_std\"]\n",
    "    dm.y_mean = merged_params[\"y_mean\"]\n",
    "    dm.y_std = merged_params[\"y_std\"]\n",
    "    dm.x_min = merged_params[\"x_min\"]\n",
    "    dm.x_max = merged_params[\"x_max\"]\n",
    "    dm.y_min = merged_params[\"y_min\"]\n",
    "    dm.y_max = merged_params[\"y_max\"]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"SVC\"):\n",
    "        if merged_params[\"log_model\"]:\n",
    "            mlflow.sklearn.autolog()\n",
    "\n",
    "        mlflow.log_param(\"kernel\", merged_params[\"kernel\"])\n",
    "        mlflow.log_param(\"C\", merged_params[\"C\"])\n",
    "        mlflow.log_param(\"tol\", merged_params[\"tol\"])\n",
    "        mlflow.log_param(\"gamma\", merged_params[\"gamma\"])\n",
    "        mlflow.log_param(\"degree\", merged_params[\"degree\"])\n",
    "        mlflow.log_param(\"coef0\", merged_params[\"coef0\"])\n",
    "        mlflow.log_param(\"arrhenius_correction\", dm.use_arrhenius_correction)\n",
    "        mlflow.log_param(\n",
    "            \"arrhenius_correction_with_factor\", dm.use_arrhenius_correction_with_factor\n",
    "        )\n",
    "        mlflow.log_param(\"min_max_scaler\", dm.use_min_max_scaler)\n",
    "        mlflow.log_param(\"standard_scaler\", dm.use_standard_scaler)\n",
    "        mlflow.log_param(\"scale_y_data\", dm.scale_y_data)\n",
    "\n",
    "        model = SVC(\n",
    "            kernel=merged_params[\"kernel\"],\n",
    "            C=merged_params[\"C\"],\n",
    "            tol=merged_params[\"tol\"],\n",
    "            gamma=merged_params[\"gamma\"],\n",
    "            degree=merged_params[\"degree\"],\n",
    "            coef0=merged_params[\"coef0\"],\n",
    "            cache_size=4000,\n",
    "            max_iter=1000000,\n",
    "            probability=False,\n",
    "        )\n",
    "\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        model.score(x_validation, y_validation.ravel())\n",
    "\n",
    "        train_maxae_temp = dm.evaluate_max_abs_error(model, x_train, y_train)\n",
    "        validation_maxae_temp = dm.evaluate_max_abs_error(\n",
    "            model, x_validation, y_validation\n",
    "        )\n",
    "        test_maxae_temp = dm.evaluate_max_abs_error(model, x_test, y_test)\n",
    "        train_mse_temp = dm.evaluate_mse(model, x_train, y_train)\n",
    "        validation_mse_temp = dm.evaluate_mse(model, x_validation, y_validation)\n",
    "        test_mse_temp = dm.evaluate_mse(model, x_test, y_test)\n",
    "        train_rmse_temp = dm.evaluate_rmse(model, x_train, y_train)\n",
    "        validation_rmse_temp = dm.evaluate_rmse(model, x_validation, y_validation)\n",
    "        test_rmse_temp = dm.evaluate_rmse(model, x_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"train_maxae_temp\", train_maxae_temp)\n",
    "        mlflow.log_metric(\"validation_maxae_temp\", validation_maxae_temp)\n",
    "        mlflow.log_metric(\"test_maxae_temp\", test_maxae_temp)\n",
    "        mlflow.log_metric(\"train_mse_temp\", train_mse_temp)\n",
    "        mlflow.log_metric(\"validation_mse_temp\", validation_mse_temp)\n",
    "        mlflow.log_metric(\"test_mse_temp\", test_mse_temp)\n",
    "        mlflow.log_metric(\"train_rmse_temp\", train_rmse_temp)\n",
    "        mlflow.log_metric(\"validation_rmse_temp\", validation_rmse_temp)\n",
    "        mlflow.log_metric(\"test_rmse_temp\", test_rmse_temp)\n",
    "\n",
    "        if merged_params[\"plot_diag\"]:\n",
    "            dm.plot_diag_during_fitting(\n",
    "                model,\n",
    "                name_of_this_run,\n",
    "                output_parameters,\n",
    "                x_test,\n",
    "                x_train,\n",
    "                x_validation,\n",
    "                data_set,\n",
    "                train_rmse_temp,\n",
    "                validation_rmse_temp,\n",
    "                test_rmse_temp,\n",
    "                merged_params,\n",
    "            )\n",
    "\n",
    "        if merged_params[\"plot_fit\"]:\n",
    "            dm.plot_fit_during_fitting(\n",
    "                model,\n",
    "                name_of_this_run,\n",
    "                input_parameters,\n",
    "                output_parameters,\n",
    "                x_train,\n",
    "                x_validation,\n",
    "                x_test,\n",
    "                y_train,\n",
    "                y_validation,\n",
    "                y_test,\n",
    "                train_rmse_temp,\n",
    "                validation_rmse_temp,\n",
    "                test_rmse_temp,\n",
    "                merged_params,\n",
    "            )\n",
    "\n",
    "        support_vectors = np.prod(np.shape(model.support_vectors_))\n",
    "        input_values = np.prod(np.shape(x_train))\n",
    "        support_vectors_not_null = support_vectors != 0\n",
    "        mlflow.log_metric(\"support_vectors\", support_vectors)\n",
    "        mlflow.log_metric(\n",
    "            \"support_vectors_percent\", support_vectors / input_values * 100\n",
    "        )\n",
    "        mlflow.log_metric(\"support_vectors_not_null\", support_vectors_not_null)\n",
    "        mlflow.log_metric(\n",
    "            \"std_rmse\", np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"max_rmse\", np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"std_times_max_rmse\",\n",
    "            np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "            * np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp]),\n",
    "        )\n",
    "\n",
    "        # fmin() minimizes the objective\n",
    "        weighted_fit_result = np.max(\n",
    "            [train_rmse_temp, validation_rmse_temp, test_rmse_temp]\n",
    "        )\n",
    "\n",
    "        mlflow.log_metric(\"weighted_fit_result\", weighted_fit_result)\n",
    "\n",
    "    return {\"loss\": weighted_fit_result, \"status\": hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "\n",
    "search_space = hyperopt.hp.choice(\n",
    "    \"SVC\",\n",
    "    [\n",
    "        {\n",
    "            \"log_model\": hyperopt.hp.choice(\"log_model\", [True]),\n",
    "            \"plot_fit\": hyperopt.hp.choice(\"plot_fit\", [True]),\n",
    "            \"plot_diag\": hyperopt.hp.choice(\"plot_diag\", [True]),\n",
    "            \"log_plot_type\": hyperopt.hp.choice(\"log_plot_type\", [\"svg\"]),\n",
    "            \"gamma\": hyperopt.hp.loguniform(\"gamma\", np.log(0.001), np.log(10)),\n",
    "            \"tol\": hyperopt.hp.loguniform(\"tol\", np.log(1e-5), np.log(100)),\n",
    "            \"C\": hyperopt.hp.loguniform(\"C\", np.log(0.01), np.log(100)),\n",
    "            \"kernel\": hyperopt.hp.choice(\"kernel\", [\"rbf\"]),\n",
    "            \"use_arrhenius_correction\": hyperopt.hp.choice(\n",
    "                \"use_arrhenius_correction\", [dm.use_arrhenius_correction]\n",
    "            ),\n",
    "            \"use_arrhenius_correction_with_factor\": hyperopt.hp.choice(\n",
    "                \"use_arrhenius_correction_with_factor\",\n",
    "                [dm.use_arrhenius_correction_with_factor],\n",
    "            ),\n",
    "            \"use_min_max_scaler\": hyperopt.hp.choice(\n",
    "                \"use_min_max_scaler\", [dm.use_min_max_scaler]\n",
    "            ),\n",
    "            \"use_standard_scaler\": hyperopt.hp.choice(\n",
    "                \"use_standard_scaler\", [dm.use_standard_scaler]\n",
    "            ),\n",
    "            \"use_scale_y_data\": hyperopt.hp.choice(\n",
    "                \"use_scale_y_data\", [dm.scale_y_data]\n",
    "            ),\n",
    "            \"x_mean\": hyperopt.hp.choice(\"x_mean\", [dm.x_mean]),\n",
    "            \"x_std\": hyperopt.hp.choice(\"x_std\", [dm.x_std]),\n",
    "            \"y_mean\": hyperopt.hp.choice(\"y_mean\", [dm.y_mean]),\n",
    "            \"y_std\": hyperopt.hp.choice(\"y_std\", [dm.y_std]),\n",
    "            \"x_min\": hyperopt.hp.choice(\"x_min\", [dm.x_min]),\n",
    "            \"x_max\": hyperopt.hp.choice(\"x_max\", [dm.x_max]),\n",
    "            \"y_min\": hyperopt.hp.choice(\"y_min\", [dm.y_min]),\n",
    "            \"y_max\": hyperopt.hp.choice(\"y_max\", [dm.y_max]),\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimization type\n",
    "\n",
    "# algo=hyperopt.tpe.suggest\n",
    "algo = hyperopt.rand.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model, you can track it in mlflow: [http://127.0.0.1:1234](http://127.0.0.1:1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timout_in_minutes = 24 * 60\n",
    "max_evals = 10\n",
    "\n",
    "# if java is installed (only recommended under linux or wsl)\n",
    "# import pyspark\n",
    "# spark_trails = hyperopt.SparkTrials(parallelism=16)\n",
    "# best_result = hyperopt.fmin(\n",
    "#     fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "#     space=search_space,\n",
    "#     algo=algo,\n",
    "#     max_evals=max_evals,\n",
    "#     timeout=timout_in_minutes * 60,\n",
    "#     trials=spark_trails,\n",
    "# )\n",
    "# if java is not available\n",
    "best_result = hyperopt.fmin(\n",
    "    fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=max_evals,\n",
    "    timeout=timout_in_minutes * 60,\n",
    ")\n",
    "\n",
    "print(hyperopt.space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best Model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run_eval = name_of_this_run\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run_eval + \".parquet\"\n",
    "df_eval = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if needed\n",
    "input_parameters_eval = input_parameters\n",
    "input_parameters_name_eval = input_parameters_name\n",
    "output_parameters_eval = output_parameters\n",
    "output_parameters_name_eval = output_parameters_name\n",
    "\n",
    "test_labels_eval = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_eval = dm.get_set(\n",
    "    df_eval,\n",
    "    output_parameters_eval,\n",
    "    feature_keys=input_parameters_eval,\n",
    "    validation_split=0.2,\n",
    "    test_split=0.1,\n",
    "    label_for_test_intervals=test_labels_eval,\n",
    "    label_name=output_parameters_name_eval,\n",
    ")\n",
    "x_train_eval, y_train_eval = data_set_eval[\"train\"]\n",
    "x_validation_eval, y_validation_eval = data_set_eval[\"validation\"]\n",
    "x_test_eval, y_test_eval = data_set_eval[\"test\"]\n",
    "\n",
    "x_train_eval = np.float32(x_train_eval)\n",
    "y_train_eval = np.float32(y_train_eval)\n",
    "x_validation_eval = np.float32(x_validation_eval)\n",
    "y_validation_eval = np.float32(y_validation_eval)\n",
    "x_test_eval = np.float32(x_test_eval)\n",
    "y_test_eval = np.float32(y_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_eval = dm.quantize_data(y_train_eval, discretize_minimum, discretize_delta)\n",
    "y_validation_eval = dm.quantize_data(\n",
    "    y_validation_eval, discretize_minimum, discretize_delta\n",
    ")\n",
    "y_test_eval = dm.quantize_data(y_test_eval, discretize_minimum, discretize_delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train_eval = dm.arrhenius_correction(x_train_eval)\n",
    "    x_validation_eval = dm.arrhenius_correction(x_validation_eval)\n",
    "    x_test_eval = dm.arrhenius_correction(x_test_eval)\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_train_eval = dm.min_max_scaler(x_train_eval, dm.x_min, dm.x_max)\n",
    "    x_validation_eval = dm.min_max_scaler(x_validation_eval, dm.x_min, dm.x_max)\n",
    "    x_test_eval = dm.min_max_scaler(x_test_eval, dm.x_min, dm.x_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train_eval = dm.standard_scaler(x_train_eval, dm.x_mean, dm.x_std)\n",
    "    x_test_eval = dm.standard_scaler(x_test_eval, dm.x_mean, dm.x_std)\n",
    "    x_validation_eval = dm.standard_scaler(x_validation_eval, dm.x_mean, dm.x_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [http://127.0.0.1:1234](http://127.0.0.1:1234) to select a fitted model. If you click on it, you can extract the run ID. It could look like this: \"ad26474e8c324f84906c9fc501928cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose a specific model\n",
    "# logged_model = 'ad26474e8c324f84906c9fc501928cae'\n",
    "# or just load the best model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "    order_by=[\"metrics.max_rmse\"],\n",
    "    filter_string=\"metrics.support_vectors_not_null = 1\",\n",
    "    max_results=1,\n",
    ")\n",
    "logged_model = runs[0].info.run_id\n",
    "\n",
    "# Load model as a Sklearn.\n",
    "run_eval = mlflow.get_run(logged_model)\n",
    "loaded_model = mlflow.sklearn.load_model(run_eval.info.artifact_uri + \"/model/\")\n",
    "\n",
    "train_rmse_temp = dm.evaluate_rmse(loaded_model, x_train_eval, y_train_eval)\n",
    "print(\"Train RMSE: \" + str(train_rmse_temp))\n",
    "validation_rmse_temp = dm.evaluate_rmse(\n",
    "    loaded_model, x_validation_eval, y_validation_eval\n",
    ")\n",
    "print(\"Validation RMSE: \" + str(validation_rmse_temp))\n",
    "test_rmse_temp = dm.evaluate_rmse(loaded_model, x_test_eval, y_test_eval)\n",
    "print(\"Test RMSE: \" + str(test_rmse_temp))\n",
    "\n",
    "unique_model_name = (\n",
    "    experiment_name\n",
    "    + \"_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \"_\"\n",
    "    + logged_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "cell_list_train = list(set(data_set_eval[\"df_train\"].index.get_level_values(0)))\n",
    "y_pred_train_eval = loaded_model.predict(x_train_eval)\n",
    "y_pred_train_eval = y_pred_train_eval.ravel()\n",
    "\n",
    "cell_list_validation = list(\n",
    "    set(data_set_eval[\"df_validation\"].index.get_level_values(0))\n",
    ")\n",
    "y_pred_validation_eval = loaded_model.predict(x_validation_eval)\n",
    "y_pred_validation_eval = y_pred_validation_eval.ravel()\n",
    "\n",
    "cell_list_test = list(set(data_set_eval[\"df_test\"].index.get_level_values(0)))\n",
    "y_pred_test_eval = loaded_model.predict(x_test_eval)\n",
    "y_pred_test_eval = y_pred_test_eval.ravel()\n",
    "\n",
    "y_train_plot = y_train_eval\n",
    "y_validation_plot = y_validation_eval\n",
    "y_test_plot = y_test_eval\n",
    "\n",
    "fig, ax = eisplot.setup_scatter(\n",
    "    data_set,\n",
    "    test_rmse_temp,\n",
    "    title=False,\n",
    "    legend=False,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    ax_xlabel=False,\n",
    "    ax_ylabel=False,\n",
    "    subplots_adjust=True,\n",
    "    add_trendline=True,\n",
    "    label=\"\",\n",
    ")\n",
    "ax.plot(\n",
    "    y_train_plot,\n",
    "    y_pred_train_eval,\n",
    "    \".\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_validation_plot,\n",
    "    y_pred_validation_eval,\n",
    "    \"1\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_test_plot,\n",
    "    y_pred_test_eval,\n",
    "    \"2\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"actual: Output\")\n",
    "ax.set_ylabel(\"predicted: Output\")\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0], [0], color=eisplot.rwth_colors.colors[(\"green\", 100)], label=\"ideal\"\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\".\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"1\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"2\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_min_plot = dm.inverse_min_max_scaler(\n",
    "        np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_min,\n",
    "        dm.x_max,\n",
    "    )\n",
    "    x_max_plot = dm.inverse_min_max_scaler(\n",
    "        np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_min,\n",
    "        dm.x_max,\n",
    "    )\n",
    "elif dm.use_standard_scaler:\n",
    "    x_min_plot = dm.inverse_standard_scaler(\n",
    "        np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_mean,\n",
    "        dm.x_std,\n",
    "    )\n",
    "    x_max_plot = dm.inverse_standard_scaler(\n",
    "        np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval))),\n",
    "        dm.x_mean,\n",
    "        dm.x_std,\n",
    "    )\n",
    "else:\n",
    "    x_min_plot = np.min(np.concatenate((x_train_eval, x_validation_eval, x_test_eval)))\n",
    "    x_max_plot = np.max(np.concatenate((x_train_eval, x_validation_eval, x_test_eval)))\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_tmp = x_min_plot\n",
    "    x_min_plot = dm.arrhenius_correction_inverse(x_max_plot)\n",
    "    x_max_plot = dm.arrhenius_correction_inverse(x_tmp)\n",
    "\n",
    "x_min_plot = x_min_plot * 0.8\n",
    "x_max_plot = x_max_plot * 1.2\n",
    "\n",
    "x_plot = np.linspace(x_min_plot, x_max_plot, 1000, dtype=np.float32)[:, None]\n",
    "\n",
    "x_plot_arrhenius = x_plot\n",
    "x_train_arrhenius = x_train_eval\n",
    "x_validation_arrhenius = x_validation_eval\n",
    "x_test_arrhenius = x_test_eval\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_plot = dm.arrhenius_correction(x_plot)\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_plot = dm.min_max_scaler(x_plot, dm.x_min, dm.x_max)\n",
    "    x_train_arrhenius = dm.inverse_min_max_scaler(x_train_arrhenius, dm.x_min, dm.x_max)\n",
    "    x_validation_arrhenius = dm.inverse_min_max_scaler(\n",
    "        x_validation_arrhenius, dm.x_min, dm.x_max\n",
    "    )\n",
    "    x_test_arrhenius = dm.inverse_min_max_scaler(x_test_arrhenius, dm.x_min, dm.x_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_plot = dm.standard_scaler(x_plot, dm.x_mean, dm.x_std)\n",
    "    x_train_arrhenius = dm.inverse_standard_scaler(\n",
    "        x_train_arrhenius, dm.x_mean, dm.x_std\n",
    "    )\n",
    "    x_validation_arrhenius = dm.inverse_standard_scaler(\n",
    "        x_validation_arrhenius, dm.x_mean, dm.x_std\n",
    "    )\n",
    "    x_test_arrhenius = dm.inverse_standard_scaler(x_test_arrhenius, dm.x_mean, dm.x_std)\n",
    "\n",
    "if dm.use_arrhenius_correction:\n",
    "    x_train_arrhenius = dm.arrhenius_correction_inverse(x_train_arrhenius)\n",
    "    x_validation_arrhenius = dm.arrhenius_correction_inverse(x_validation_arrhenius)\n",
    "    x_test_arrhenius = dm.arrhenius_correction_inverse(x_test_arrhenius)\n",
    "\n",
    "y_svr = loaded_model.predict(x_plot)\n",
    "\n",
    "ax.plot(\n",
    "    x_plot_arrhenius,\n",
    "    y_svr,\n",
    "    lw=2,\n",
    "    label=\"Regression\",\n",
    "    color=eisplot.rwth_colors.colors[(\"bordeaux\", 100)],\n",
    ")\n",
    "ax.scatter(\n",
    "    x_train_arrhenius,\n",
    "    y_train_plot,\n",
    "    marker=\".\",\n",
    "    label=\"train\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    x_validation_arrhenius,\n",
    "    y_validation_plot,\n",
    "    marker=\"1\",\n",
    "    label=\"validation\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.scatter(\n",
    "    x_test_arrhenius,\n",
    "    y_test_plot,\n",
    "    marker=\"2\",\n",
    "    label=\"test\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Output Value\")\n",
    "ax.set_xlabel(\"Input Value\")\n",
    "ax.grid()\n",
    "\n",
    "ax.legend(loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    3,\n",
    "    1,\n",
    "    figsize=(7 * eisplot.cm, 16 * eisplot.cm),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    "    layout=\"compressed\",\n",
    ")\n",
    "\n",
    "vmin = 0\n",
    "vmax = 1\n",
    "norm = mpl.colors.Normalize(vmin, vmax)\n",
    "\n",
    "classes = np.unique(\n",
    "    np.concatenate(\n",
    "        [\n",
    "            y_train_eval.ravel(),\n",
    "            y_pred_train_eval.ravel(),\n",
    "            y_validation_eval.ravel(),\n",
    "            y_pred_validation_eval.ravel(),\n",
    "            y_test_eval.ravel(),\n",
    "            y_pred_test_eval.ravel(),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "cm_train = confusion_matrix(\n",
    "    y_train_eval, y_pred_train_eval, normalize=\"true\", labels=classes\n",
    ")\n",
    "cm_validation = confusion_matrix(\n",
    "    y_validation_eval, y_pred_validation_eval, normalize=\"true\", labels=classes\n",
    ")\n",
    "cm_test = confusion_matrix(\n",
    "    y_test_eval, y_pred_test_eval, normalize=\"true\", labels=classes\n",
    ")\n",
    "\n",
    "axes[0] = sns.heatmap(\n",
    "    cm_train,\n",
    "    cmap=\"turbo\",\n",
    "    ax=axes[0],\n",
    "    cbar=False,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    square=True,\n",
    "    annot=cm_train,\n",
    "    center=0.5,\n",
    "    yticklabels=classes,\n",
    "    xticklabels=classes,\n",
    ")  # ,fmt='.1f')\n",
    "axes[0].tick_params(axis=\"y\", rotation=0)\n",
    "axes[0].set_ylabel(\"True label\")\n",
    "axes[0].title.set_text(\"Train\")\n",
    "axes[0].set_xlabel(\"\")\n",
    "\n",
    "axes[1] = sns.heatmap(\n",
    "    cm_validation,\n",
    "    cmap=\"turbo\",\n",
    "    ax=axes[1],\n",
    "    cbar=False,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    square=True,\n",
    "    annot=cm_validation,\n",
    "    center=0.5,\n",
    "    yticklabels=classes,\n",
    "    xticklabels=classes,\n",
    ")  # ,fmt='.1f')\n",
    "axes[1].tick_params(axis=\"y\", rotation=0)\n",
    "axes[1].set_ylabel(\"True label\")\n",
    "axes[1].title.set_text(\"Validation\")\n",
    "axes[1].set_xlabel(\"\")\n",
    "\n",
    "axes[2] = sns.heatmap(\n",
    "    cm_test,\n",
    "    cmap=\"turbo\",\n",
    "    ax=axes[2],\n",
    "    cbar=False,\n",
    "    vmin=vmin,\n",
    "    vmax=vmax,\n",
    "    square=True,\n",
    "    annot=cm_test,\n",
    "    center=0.5,\n",
    "    yticklabels=classes,\n",
    "    xticklabels=classes,\n",
    ")  # ,fmt='.1f')\n",
    "axes[2].tick_params(axis=\"y\", rotation=0)\n",
    "axes[2].tick_params(axis=\"x\", rotation=90)\n",
    "axes[2].set_ylabel(\"True label\")\n",
    "axes[2].title.set_text(\"Test\")\n",
    "axes[2].set_xlabel(\"Predicted label\")\n",
    "\n",
    "\n",
    "cmap = mpl.cm.ScalarMappable(norm=norm, cmap=mpl.cm.turbo)\n",
    "cmap.set_array([])\n",
    "cbar = fig.colorbar(cmap, ax=axes, location=\"top\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert, Export, Test and Validate with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = [(\"float_input\", FloatTensorType([None, len(x_train[0])]))]\n",
    "onnx_filename = \"microcontroller_eis_network/onnx_export/\" + unique_model_name + \".onnx\"\n",
    "onx = convert_sklearn(loaded_model, initial_types=input_type)\n",
    "with open(onnx_filename, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_filename, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval})[0]\n",
    "y_test_eval_ref = y_test_eval.copy()\n",
    "\n",
    "diff = pred_onx.ravel() - y_test_eval_ref.ravel()\n",
    "print(np.max(np.abs(diff)))\n",
    "print(np.mean(diff))\n",
    "print(np.std(diff))\n",
    "print(np.sqrt(np.mean((diff) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_eval_float32 = x_test_eval.astype(np.float32)\n",
    "\n",
    "pred_sklearn = loaded_model.predict(x_test_eval_float32)\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval_float32})[0].ravel()\n",
    "\n",
    "diff = pred_sklearn.ravel() - pred_onx.ravel()\n",
    "print(\"Max difference between scikit-learn and ONNX predictions:\", np.max(np.abs(diff)))\n",
    "print(\"Mean difference between scikit-learn and ONNX predictions:\", np.mean(diff))\n",
    "print(\"RMSE of differences:\", np.sqrt(np.mean(diff**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the SVC on the ÂµC is not yet implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further comparison of different fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()\n",
    "experiment_id = mlflow_exp.experiment_id\n",
    "experiment_id\n",
    "\n",
    "for exp in mlflow.search_experiments():\n",
    "    if exp.experiment_id == experiment_id:\n",
    "        experiment_tmp = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "        experiment_list = pd.concat([experiment_list, experiment_tmp])\n",
    "\n",
    "experiment_list = experiment_list.reset_index(drop=True)\n",
    "experiment_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_values = [\n",
    "    experiment_list[\"metrics.train_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.test_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.train_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.train_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_rmse_temp\"].values,\n",
    "    experiment_list[\"params.kernel\"].values,\n",
    "    experiment_list[\"params.C\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.tol\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.gamma\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.degree\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.coef0\"].values.astype(np.float64),\n",
    "]\n",
    "df_experiment = pd.DataFrame(\n",
    "    np.transpose(scatter_values),\n",
    "    columns=[\n",
    "        \"Train MAXAE in K\",\n",
    "        \"Validation MAXAE in K\",\n",
    "        \"Test MAXAE in K\",\n",
    "        \"Train MSE in K^2\",\n",
    "        \"Validation MSE in K^2\",\n",
    "        \"Test MSE in K^2\",\n",
    "        \"Train RMSE in K\",\n",
    "        \"Validation RMSE in K\",\n",
    "        \"Test RMSE in K\",\n",
    "        \"Kernel\",\n",
    "        \"C\",\n",
    "        \"Tolerance\",\n",
    "        \"Gamma\",\n",
    "        \"Degree\",\n",
    "        \"Coef0\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the error if necessary\n",
    "df_experiment[df_experiment[\"Test RMSE in K\"] > 10] = np.nan\n",
    "df_experiment = df_experiment.dropna(subset=[\"Test RMSE in K\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_experiment.drop(columns=[\"Kernel\"]).corr()\n",
    "corr.style.background_gradient(cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(unique_model_name)\n",
    "except:\n",
    "    unique_model_name = (\n",
    "        experiment_name\n",
    "        + \"_\"\n",
    "        + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filepath = r\"./mlruns/\" + unique_model_name + \".parquet\"\n",
    "experiment_list.to_parquet(destination_filepath, compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12 * eisplot.cm, 12 * eisplot.cm), sharex=True)\n",
    "\n",
    "variables = [\"\", \"C\", \"Tolerance\", \"Gamma\"]\n",
    "\n",
    "for variable_idx, variable in enumerate(variables):\n",
    "    if variable_idx == 0:\n",
    "        continue\n",
    "    plot_column = np.floor(variable_idx / 2).astype(\"int\")\n",
    "    plot_row = variable_idx - 2 * plot_column\n",
    "\n",
    "    concave_hull_ratio = 0.25\n",
    "\n",
    "    min_error = np.min(\n",
    "        [\n",
    "            df_experiment[\"Train RMSE in K\"].values,\n",
    "            df_experiment[\"Validation RMSE in K\"].values,\n",
    "            df_experiment[\"Test RMSE in K\"].values,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Train RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Train RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Validation RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Validation RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Test RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Test RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    axs[plot_column, plot_row].set_ylabel(variable)\n",
    "    axs[plot_column, plot_row].set_yscale(\"log\")\n",
    "    axs[plot_column, plot_row].grid()\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\":\",\n",
    "        color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    "        label=\"selected value\",\n",
    "        alpha=1.0,\n",
    "    ),\n",
    "]\n",
    "fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper center\",\n",
    "    scatterpoints=1,\n",
    "    ncol=4,\n",
    ")\n",
    "\n",
    "\n",
    "axs[1, 0].set_xlabel(\"RMSE in K\")\n",
    "axs[1, 1].set_xlabel(\"RMSE in K\")\n",
    "fig.tight_layout()\n",
    "\n",
    "x_values = np.array([axs[1, 1].get_xlim()[0] + 1, axs[1, 1].get_xlim()[1] - 1])\n",
    "\n",
    "axs[0, 0].remove()\n",
    "\n",
    "axs[0, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"C\"]), float(run_eval.data.params[\"C\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"tol\"]), float(run_eval.data.params[\"tol\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"gamma\"]), float(run_eval.data.params[\"gamma\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
