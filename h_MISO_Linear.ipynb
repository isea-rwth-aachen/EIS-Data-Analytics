{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISO Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to see the results you should start the MLflow ui separately**:\n",
    "1. Open a prompt/terminal and navigate to the path of this project\n",
    "2. Activate the virtual environment:  \n",
    "    (Windows: ```.venv\\eis_data_analytics\\Scripts\\activate```,  \n",
    "    Linux/Mac: ```.venv/eis_data_analytics/bin/activate```)\n",
    "3. Now start MLflow with ```mlflow server --port 1234``` consider to add e.g.: ```--workers=16 --gunicorn-opts='--timeout 600'```\n",
    "4. Open [http://127.0.0.1:1234](http://127.0.0.1:1234) in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "from modules import dataset_manipulation as dm\n",
    "from modules import eisplot as eisplot\n",
    "from modules.eisplot import plt\n",
    "from modules.eisplot import mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import mlflow\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from skl2onnx import convert_sklearn, update_registered_converter\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx.common.shape_calculator import calculate_linear_regressor_output_shapes\n",
    "import onnxruntime as rt\n",
    "\n",
    "## if you have installed latex and want to use it for plots, uncomment the following 3 lines\n",
    "# mpl.rcParams.update({\"text.usetex\": True,'savefig.format':'pdf'})\n",
    "# mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# mpl.rc('text.latex', preamble=r'\\usepackage{underscore}')\n",
    "\n",
    "## save figures e.g. with:\n",
    "# plot_name = \"custom_3D_plot\"\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run = \"example_data\"\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run + \".parquet\"\n",
    "df = pd.read_parquet(destination_filepath)\n",
    "destination_filepath = r\"./data/key_lookup/key_lookup_\" + name_of_this_run + \".parquet\"\n",
    "key_lookup_df = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be any of the following:\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of one frequency with polynomial features\n",
    "# input_parameters = []\n",
    "# frequency = 100\n",
    "# input_parameters += [key_lookup_df[\"EIS_Z_abs\"].loc[np.argmin(\n",
    "#     np.abs(key_lookup_df[\"frequency\"].values - frequency))]]\n",
    "# # Give it a Name (filename friendly)\n",
    "# input_parameters_name = \"Z_abs_100hzPoly5\"\n",
    "# polynomial_degree = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parameters = []\n",
    "input_parameters += key_lookup_df[\"EIS_Z_abs\"].to_list()\n",
    "# input_parameters += key_lookup_df[\"EIS_Z_phase\"].to_list()\n",
    "# input_parameters.append(\"Voltage\")\n",
    "# Give it a Name (filename friendly)\n",
    "input_parameters_name = \"Z_abs\"\n",
    "\n",
    "# add polynomial features if desired, otherwise set to 1\n",
    "polynomial_degree = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOC\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_parameters = []\n",
    "# output_parameters += [\"SOH\"]\n",
    "# # Give it a Name (filename friendly)\n",
    "# output_parameters_name = \"SOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"Temperature\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"Temperature\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [\"Temperature\"]\n",
    "output_intervals_for_test = {\"Temperature\": [[4, 6], [34, 36]]}\n",
    "\n",
    "# convert to training arrays\n",
    "data_set = dm.get_set(\n",
    "    df,\n",
    "    output_parameters,\n",
    "    feature_keys=input_parameters,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test,\n",
    "    label_for_test_intervals=test_labels,\n",
    "    label_name=output_parameters_name,\n",
    ")\n",
    "x_train, y_train = data_set[\"train\"]\n",
    "x_validation, y_validation = data_set[\"validation\"]\n",
    "x_test, y_test = data_set[\"test\"]\n",
    "\n",
    "# convert everything to float32\n",
    "x_train = np.float32(x_train)\n",
    "y_train = np.float32(y_train)\n",
    "x_validation = np.float32(x_validation)\n",
    "y_validation = np.float32(y_validation)\n",
    "x_test = np.float32(x_test)\n",
    "y_test = np.float32(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.use_arrhenius_correction = True\n",
    "dm.use_arrhenius_correction_with_factor = False\n",
    "dm.arrhenius_b = -15.47\n",
    "dm.arrhenius_c = 1.30\n",
    "# [dm.arrhenius_correction_inverse(dm.arrhenius_correction(i))\n",
    "#  for i in [0.01, 0.1, 1, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train = dm.arrhenius_correction(x_train)\n",
    "    x_validation = dm.arrhenius_correction(x_validation)\n",
    "    x_test = dm.arrhenius_correction(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parameters_backup = input_parameters.copy()\n",
    "if polynomial_degree > 1:\n",
    "    poly = PolynomialFeatures(\n",
    "        degree=polynomial_degree, include_bias=False, interaction_only=False\n",
    "    )\n",
    "    x_train = poly.fit_transform(x_train)\n",
    "    x_validation = poly.fit_transform(x_validation)\n",
    "    x_test = poly.fit_transform(x_test)\n",
    "    input_parameters = poly.get_feature_names_out(input_parameters).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select Scaler to use (Only one!)\n",
    "dm.use_min_max_scaler = True\n",
    "dm.use_standard_scaler = False\n",
    "dm.scale_y_data = True\n",
    "# [dm.inverse_min_max_scaler(dm.min_max_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# [dm.inverse_standard_scaler(dm.standard_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "## Standard Scaler\n",
    "dm.x_mean = np.mean(x_train)\n",
    "dm.x_std = np.std(x_train)\n",
    "dm.y_mean = np.mean(y_train)\n",
    "dm.y_std = np.std(y_train)\n",
    "## Min Max scaler\n",
    "dm.x_min = np.min(x_train)\n",
    "dm.x_max = np.max(x_train)\n",
    "if dm.scale_y_data:\n",
    "    dm.y_min = np.min(y_train)\n",
    "    dm.y_max = np.max(y_train)\n",
    "else:\n",
    "    dm.y_min = np.array(0, dtype=np.float32)\n",
    "    dm.y_max = np.array(1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_min_max_scaler:\n",
    "    x_train = dm.min_max_scaler(x_train, dm.x_min, dm.x_max)\n",
    "    x_validation = dm.min_max_scaler(x_validation, dm.x_min, dm.x_max)\n",
    "    x_test = dm.min_max_scaler(x_test, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.min_max_scaler(y_train, dm.y_min, dm.y_max)\n",
    "        y_validation = dm.min_max_scaler(y_validation, dm.y_min, dm.y_max)\n",
    "        y_test = dm.min_max_scaler(y_test, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train = dm.standard_scaler(x_train, dm.x_mean, dm.x_std)\n",
    "    x_test = dm.standard_scaler(x_test, dm.x_mean, dm.x_std)\n",
    "    x_validation = dm.standard_scaler(x_validation, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.standard_scaler(y_train, dm.y_mean, dm.y_std)\n",
    "        y_validation = dm.standard_scaler(y_validation, dm.y_mean, dm.y_std)\n",
    "        y_test = dm.standard_scaler(y_test, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is logged in mlflow, create a new experiment\n",
    "experiment_name = (\n",
    "    name_of_this_run\n",
    "    + \"_\"\n",
    "    + \"MISO_Linear_\"\n",
    "    + input_parameters_name\n",
    "    + \"_\"\n",
    "    + output_parameters_name\n",
    ")\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=mlflow_exp.experiment_id, run_name=\"Linear\"):\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    mlflow.log_param(\"arrhenius_correction\", dm.use_arrhenius_correction)\n",
    "    mlflow.log_param(\n",
    "        \"arrhenius_correction_with_factor\", dm.use_arrhenius_correction_with_factor\n",
    "    )\n",
    "    mlflow.log_param(\"min_max_scaler\", dm.use_min_max_scaler)\n",
    "    mlflow.log_param(\"standard_scaler\", dm.use_standard_scaler)\n",
    "    mlflow.log_param(\"dm.scale_y_data\", dm.scale_y_data)\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    model.score(x_validation, y_validation)\n",
    "\n",
    "    train_maxae_temp = dm.evaluate_max_abs_error(model, x_train, y_train)\n",
    "    validation_maxae_temp = dm.evaluate_max_abs_error(model, x_validation, y_validation)\n",
    "    test_maxae_temp = dm.evaluate_max_abs_error(model, x_test, y_test)\n",
    "    train_mse_temp = dm.evaluate_mse(model, x_train, y_train)\n",
    "    validation_mse_temp = dm.evaluate_mse(model, x_validation, y_validation)\n",
    "    test_mse_temp = dm.evaluate_mse(model, x_test, y_test)\n",
    "    train_rmse_temp = dm.evaluate_rmse(model, x_train, y_train)\n",
    "    validation_rmse_temp = dm.evaluate_rmse(model, x_validation, y_validation)\n",
    "    test_rmse_temp = dm.evaluate_rmse(model, x_test, y_test)\n",
    "\n",
    "    mlflow.log_metric(\"train_maxae_temp\", train_maxae_temp)\n",
    "    mlflow.log_metric(\"validation_maxae_temp\", validation_maxae_temp)\n",
    "    mlflow.log_metric(\"test_maxae_temp\", test_maxae_temp)\n",
    "    mlflow.log_metric(\"train_mse_temp\", train_mse_temp)\n",
    "    mlflow.log_metric(\"validation_mse_temp\", validation_mse_temp)\n",
    "    mlflow.log_metric(\"test_mse_temp\", test_mse_temp)\n",
    "    mlflow.log_metric(\"train_rmse_temp\", train_rmse_temp)\n",
    "    mlflow.log_metric(\"validation_rmse_temp\", validation_rmse_temp)\n",
    "    mlflow.log_metric(\"test_rmse_temp\", test_rmse_temp)\n",
    "\n",
    "    merged_params = {\"log_plot_type\": \".svg\"}\n",
    "    dm.plot_diag_during_fitting(\n",
    "        model,\n",
    "        name_of_this_run,\n",
    "        output_parameters,\n",
    "        x_test,\n",
    "        x_train,\n",
    "        x_validation,\n",
    "        data_set,\n",
    "        train_rmse_temp,\n",
    "        validation_rmse_temp,\n",
    "        test_rmse_temp,\n",
    "        merged_params,\n",
    "    )\n",
    "\n",
    "    mlflow.log_metric(\n",
    "        \"std_rmse\", np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "    )\n",
    "    mlflow.log_metric(\n",
    "        \"max_rmse\", np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "    )\n",
    "    mlflow.log_metric(\n",
    "        \"std_times_max_rmse\",\n",
    "        np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        * np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp]),\n",
    "    )\n",
    "\n",
    "    weighted_fit_result = np.max(\n",
    "        [train_rmse_temp, validation_rmse_temp, test_rmse_temp]\n",
    "    )\n",
    "\n",
    "    mlflow.log_metric(\"weighted_fit_result\", weighted_fit_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = \"\\n\".join(\n",
    "    [\n",
    "        f\"{param} = {intercept:.3f} + \"\n",
    "        + \" + \".join(\n",
    "            [f\"{coef:.3f}*{feat}\" for coef, feat in zip(coef_vector, input_parameters)]\n",
    "        )\n",
    "        for param, intercept, coef_vector in zip(\n",
    "            output_parameters, model.intercept_, model.coef_\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best Model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run_eval = name_of_this_run\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run_eval + \".parquet\"\n",
    "df_eval = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if needed\n",
    "input_parameters_eval = input_parameters_backup\n",
    "input_parameters_name_eval = input_parameters_name\n",
    "output_parameters_eval = output_parameters\n",
    "output_parameters_name_eval = output_parameters_name\n",
    "\n",
    "test_labels_eval = test_labels\n",
    "output_intervals_for_test_eval = output_intervals_for_test\n",
    "polynomial_degree_eval = polynomial_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_eval = dm.get_set(\n",
    "    df_eval,\n",
    "    output_parameters_eval,\n",
    "    feature_keys=input_parameters_eval,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test_eval,\n",
    "    label_for_test_intervals=test_labels_eval,\n",
    "    label_name=output_parameters_name_eval,\n",
    ")\n",
    "x_train_eval, y_train_eval = data_set_eval[\"train\"]\n",
    "x_validation_eval, y_validation_eval = data_set_eval[\"validation\"]\n",
    "x_test_eval, y_test_eval = data_set_eval[\"test\"]\n",
    "\n",
    "x_train_eval = np.float32(x_train_eval)\n",
    "y_train_eval = np.float32(y_train_eval)\n",
    "x_validation_eval = np.float32(x_validation_eval)\n",
    "y_validation_eval = np.float32(y_validation_eval)\n",
    "x_test_eval = np.float32(x_test_eval)\n",
    "y_test_eval = np.float32(y_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train_eval = dm.arrhenius_correction(x_train_eval)\n",
    "    x_validation_eval = dm.arrhenius_correction(x_validation_eval)\n",
    "    x_test_eval = dm.arrhenius_correction(x_test_eval)\n",
    "\n",
    "if polynomial_degree_eval > 1:\n",
    "    poly = PolynomialFeatures(\n",
    "        degree=polynomial_degree_eval, include_bias=False, interaction_only=False\n",
    "    )\n",
    "    x_train_eval = poly.fit_transform(x_train_eval)\n",
    "    x_validation_eval = poly.fit_transform(x_validation_eval)\n",
    "    x_test_eval = poly.fit_transform(x_test_eval)\n",
    "    input_parameters_eval = poly.get_feature_names_out(input_parameters_eval).tolist()\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_train_eval = dm.min_max_scaler(x_train_eval, dm.x_min, dm.x_max)\n",
    "    x_validation_eval = dm.min_max_scaler(x_validation_eval, dm.x_min, dm.x_max)\n",
    "    x_test_eval = dm.min_max_scaler(x_test_eval, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_eval = dm.min_max_scaler(y_validation_eval, dm.y_min, dm.y_max)\n",
    "        y_test_eval = dm.min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train_eval = dm.standard_scaler(x_train_eval, dm.x_mean, dm.x_std)\n",
    "    x_test_eval = dm.standard_scaler(x_test_eval, dm.x_mean, dm.x_std)\n",
    "    x_validation_eval = dm.standard_scaler(x_validation_eval, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_eval = dm.standard_scaler(y_validation_eval, dm.y_mean, dm.y_std)\n",
    "        y_test_eval = dm.standard_scaler(y_test_eval, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [http://127.0.0.1:1234](http://127.0.0.1:1234) to select a fitted model. If you click on it, you can extract the run ID. It could look like this: \"ad26474e8c324f84906c9fc501928cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose a specific model\n",
    "# logged_model = 'ad26474e8c324f84906c9fc501928cae'\n",
    "# or just load the best model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "    order_by=[\"metrics.max_rmse\"],\n",
    "    max_results=1,\n",
    ")\n",
    "logged_model = runs[0].info.run_id\n",
    "\n",
    "# Load model as a Sklearn.\n",
    "run_eval = mlflow.get_run(logged_model)\n",
    "loaded_model = mlflow.sklearn.load_model(run_eval.info.artifact_uri + \"/model/\")\n",
    "\n",
    "train_rmse_temp = dm.evaluate_rmse(loaded_model, x_train_eval, y_train_eval)\n",
    "print(\"Train RMSE: \" + str(train_rmse_temp))\n",
    "validation_rmse_temp = dm.evaluate_rmse(\n",
    "    loaded_model, x_validation_eval, y_validation_eval\n",
    ")\n",
    "print(\"Validation RMSE: \" + str(validation_rmse_temp))\n",
    "test_rmse_temp = dm.evaluate_rmse(loaded_model, x_test_eval, y_test_eval)\n",
    "print(\"Test RMSE: \" + str(test_rmse_temp))\n",
    "\n",
    "formula = \"\\n\".join(\n",
    "    [\n",
    "        f\"{param} = {intercept:.3f} + \"\n",
    "        + \" + \".join(\n",
    "            [f\"{coef:.3f}*{feat}\" for coef, feat in zip(coef_vector, input_parameters)]\n",
    "        )\n",
    "        for param, intercept, coef_vector in zip(\n",
    "            output_parameters_eval, loaded_model.intercept_, loaded_model.coef_\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(formula)\n",
    "\n",
    "unique_model_name = (\n",
    "    experiment_name\n",
    "    + \"_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \"_\"\n",
    "    + logged_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "cell_list_train = list(set(data_set_eval[\"df_train\"].index.get_level_values(0)))\n",
    "y_pred_train_eval = loaded_model.predict(x_train_eval)\n",
    "y_pred_train_eval = y_pred_train_eval.ravel()\n",
    "\n",
    "cell_list_validation = list(\n",
    "    set(data_set_eval[\"df_validation\"].index.get_level_values(0))\n",
    ")\n",
    "y_pred_validation_eval = loaded_model.predict(x_validation_eval)\n",
    "y_pred_validation_eval = y_pred_validation_eval.ravel()\n",
    "\n",
    "cell_list_test = list(set(data_set_eval[\"df_test\"].index.get_level_values(0)))\n",
    "y_pred_test_eval = loaded_model.predict(x_test_eval)\n",
    "y_pred_test_eval = y_pred_test_eval.ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        y_pred_train_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_train_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_test_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_train_plot = dm.inverse_min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_plot = dm.inverse_min_max_scaler(\n",
    "            y_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_test_plot = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        y_pred_train_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_train_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_test_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_train_plot = dm.inverse_standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_plot = dm.inverse_standard_scaler(\n",
    "            y_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_test_plot = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_train_plot = y_train_eval\n",
    "    y_validation_plot = y_validation_eval\n",
    "    y_test_plot = y_test_eval\n",
    "\n",
    "fig, ax = eisplot.setup_scatter(\n",
    "    data_set,\n",
    "    test_rmse_temp,\n",
    "    title=False,\n",
    "    legend=False,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    ax_xlabel=False,\n",
    "    ax_ylabel=False,\n",
    "    subplots_adjust=True,\n",
    "    add_trendline=True,\n",
    "    label=\"\",\n",
    ")\n",
    "ax.plot(\n",
    "    y_train_plot,\n",
    "    y_pred_train_eval,\n",
    "    \".\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_validation_plot,\n",
    "    y_pred_validation_eval,\n",
    "    \"1\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_test_plot,\n",
    "    y_pred_test_eval,\n",
    "    \"2\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"actual: Output\")\n",
    "ax.set_ylabel(\"predicted: Output\")\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0], [0], color=eisplot.rwth_colors.colors[(\"green\", 100)], label=\"ideal\"\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\".\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"1\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"2\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert, Export, Test and Validate with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_linear_regression(scope, operator, container):\n",
    "    from skl2onnx.proto import onnx_proto\n",
    "    from skl2onnx.common._apply_operation import apply_add, apply_matmul\n",
    "\n",
    "    op = operator.raw_operator\n",
    "\n",
    "    coef = op.coef_\n",
    "    intercept = op.intercept_\n",
    "\n",
    "    if coef.ndim == 1:\n",
    "        coef = coef.reshape(-1, 1)\n",
    "    else:\n",
    "        coef = coef.T\n",
    "\n",
    "    intercept = intercept.flatten()\n",
    "    coef = coef.astype(float)\n",
    "    intercept = intercept.astype(float)\n",
    "    coef_name = scope.get_unique_variable_name(\"coef\")\n",
    "    intercept_name = scope.get_unique_variable_name(\"intercept\")\n",
    "\n",
    "    container.add_initializer(\n",
    "        coef_name, onnx_proto.TensorProto.FLOAT, coef.shape, coef.flatten()\n",
    "    )\n",
    "    container.add_initializer(\n",
    "        intercept_name, onnx_proto.TensorProto.FLOAT, intercept.shape, intercept\n",
    "    )\n",
    "    matmul_output_name = scope.get_unique_variable_name(\"matmul_output\")\n",
    "    apply_matmul(\n",
    "        scope, [operator.inputs[0].full_name, coef_name], matmul_output_name, container\n",
    "    )\n",
    "    apply_add(\n",
    "        scope,\n",
    "        [matmul_output_name, intercept_name],\n",
    "        operator.outputs[0].full_name,\n",
    "        container,\n",
    "    )\n",
    "\n",
    "\n",
    "update_registered_converter(\n",
    "    LinearRegression,\n",
    "    \"SklearnLinearRegression\",\n",
    "    calculate_linear_regressor_output_shapes,\n",
    "    convert_linear_regression,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = [(\"float_input\", FloatTensorType([None, len(x_train[0])]))]\n",
    "onnx_filename = \"microcontroller_eis_network/onnx_export/\" + unique_model_name + \".onnx\"\n",
    "onx = convert_sklearn(loaded_model, initial_types=input_type)\n",
    "with open(onnx_filename, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_filename, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval})[0]\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "        y_test_eval_ref = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "        y_test_eval_ref = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_test_eval_ref = y_test_eval.copy()\n",
    "\n",
    "diff = pred_onx.ravel() - y_test_eval_ref.ravel()\n",
    "print(np.max(np.abs(diff)))\n",
    "print(np.mean(diff))\n",
    "print(np.std(diff))\n",
    "print(np.sqrt(np.mean((diff) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_eval_float32 = x_test_eval.astype(np.float32)\n",
    "\n",
    "pred_sklearn = loaded_model.predict(x_test_eval_float32)\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval_float32})[0].ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_sklearn = dm.inverse_min_max_scaler(pred_sklearn, dm.y_min, dm.y_max)\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_sklearn = dm.inverse_standard_scaler(pred_sklearn, dm.y_mean, dm.y_std)\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "\n",
    "diff = pred_sklearn.ravel() - pred_onx.ravel()\n",
    "print(\"Max difference between scikit-learn and ONNX predictions:\", np.max(np.abs(diff)))\n",
    "print(\"Mean difference between scikit-learn and ONNX predictions:\", np.mean(diff))\n",
    "print(\"RMSE of differences:\", np.sqrt(np.mean(diff**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the test data for the microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_path = \"microcontroller_eis_network/Core/Inc/\"\n",
    "dm.create_test_header_file(\n",
    "    data_set_eval,\n",
    "    header_path,\n",
    "    unique_model_name,\n",
    "    polynomial_degree=polynomial_degree_eval,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further comparison of different fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()\n",
    "experiment_id = mlflow_exp.experiment_id\n",
    "experiment_id\n",
    "\n",
    "for exp in mlflow.search_experiments():\n",
    "    if exp.experiment_id == experiment_id:\n",
    "        experiment_tmp = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "        experiment_list = pd.concat([experiment_list, experiment_tmp])\n",
    "\n",
    "experiment_list = experiment_list.reset_index(drop=True)\n",
    "experiment_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_values = [\n",
    "    experiment_list[\"metrics.train_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.test_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.train_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.train_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_rmse_temp\"].values,\n",
    "]\n",
    "df_experiment = pd.DataFrame(\n",
    "    np.transpose(scatter_values),\n",
    "    columns=[\n",
    "        \"Train MAXAE in K\",\n",
    "        \"Validation MAXAE in K\",\n",
    "        \"Test MAXAE in K\",\n",
    "        \"Train MSE in K^2\",\n",
    "        \"Validation MSE in K^2\",\n",
    "        \"Test MSE in K^2\",\n",
    "        \"Train RMSE in K\",\n",
    "        \"Validation RMSE in K\",\n",
    "        \"Test RMSE in K\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filepath = r\"./mlruns/\" + unique_model_name + \".parquet\"\n",
    "experiment_list.to_parquet(destination_filepath, compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
