{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MISO Multi-layer Perceptron (MLP) Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to see the results you should start the MLflow ui separately**:\n",
    "1. Open a prompt/terminal and navigate to the path of this project\n",
    "2. Activate the virtual environment:  \n",
    "    (Windows: ```.venv\\eis_data_analytics\\Scripts\\activate```,  \n",
    "    Linux/Mac: ```.venv/eis_data_analytics/bin/activate```)\n",
    "3. Now start MLflow with ```mlflow server --port 1234``` consider to add e.g.: ```--workers=16 --gunicorn-opts='--timeout 600'```\n",
    "4. Open [http://127.0.0.1:1234](http://127.0.0.1:1234) in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "from modules import dataset_manipulation as dm\n",
    "from modules import eisplot as eisplot\n",
    "from modules.eisplot import plt\n",
    "from modules.eisplot import mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import hyperopt\n",
    "import mlflow\n",
    "import shapely\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "import onnxruntime as rt\n",
    "\n",
    "## if you have installed latex and want to use it for plots, uncomment the following 3 lines\n",
    "# mpl.rcParams.update({\"text.usetex\": True,'savefig.format':'pdf'})\n",
    "# mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# mpl.rc('text.latex', preamble=r'\\usepackage{underscore}')\n",
    "\n",
    "## save figures e.g. with:\n",
    "# plot_name = \"custom_3D_plot\"\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run = \"example_data\"\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run + \".parquet\"\n",
    "df = pd.read_parquet(destination_filepath)\n",
    "destination_filepath = r\"./data/key_lookup/key_lookup_\" + name_of_this_run + \".parquet\"\n",
    "key_lookup_df = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can be any of the following:\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "df.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_parameters = []\n",
    "input_parameters += key_lookup_df[\"EIS_Z_abs\"].to_list()\n",
    "# input_parameters += key_lookup_df[\"EIS_Z_phase\"].to_list()\n",
    "# input_parameters.append(\"Voltage\")\n",
    "# Give it a Name (filename friendly)\n",
    "input_parameters_name = \"Z_abs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Output Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"SOC\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"SOC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"SOH\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"SOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameters = []\n",
    "output_parameters += [\"Temperature\"]\n",
    "# Give it a Name (filename friendly)\n",
    "output_parameters_name = \"Temp\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split up the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = [\"Temperature\"]\n",
    "output_intervals_for_test = {\"Temperature\": [[4, 6], [34, 36]]}\n",
    "\n",
    "# convert to training arrays\n",
    "data_set = dm.get_set(\n",
    "    df,\n",
    "    output_parameters,\n",
    "    feature_keys=input_parameters,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test,\n",
    "    label_for_test_intervals=test_labels,\n",
    "    label_name=output_parameters_name,\n",
    ")\n",
    "x_train, y_train = data_set[\"train\"]\n",
    "x_validation, y_validation = data_set[\"validation\"]\n",
    "x_test, y_test = data_set[\"test\"]\n",
    "\n",
    "# convert everything to float32\n",
    "x_train = np.float32(x_train)\n",
    "y_train = np.float32(y_train)\n",
    "x_validation = np.float32(x_validation)\n",
    "y_validation = np.float32(y_validation)\n",
    "x_test = np.float32(x_test)\n",
    "y_test = np.float32(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dm.use_arrhenius_correction = True\n",
    "dm.use_arrhenius_correction_with_factor = False\n",
    "dm.arrhenius_b = -15.47\n",
    "dm.arrhenius_c = 1.30\n",
    "# [dm.arrhenius_correction_inverse(dm.arrhenius_correction(i))\n",
    "#  for i in [0.01, 0.1, 1, 10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train = dm.arrhenius_correction(x_train)\n",
    "    x_validation = dm.arrhenius_correction(x_validation)\n",
    "    x_test = dm.arrhenius_correction(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select Scaler to use (Only one!)\n",
    "dm.use_min_max_scaler = True\n",
    "dm.use_standard_scaler = False\n",
    "dm.scale_y_data = True\n",
    "# [dm.inverse_min_max_scaler(dm.min_max_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# [dm.inverse_standard_scaler(dm.standard_scaler(i, dm.x_min, dm.x_max), dm.x_min, dm.x_max)\n",
    "#  for i in [0.01, 0.1, 1, 10]]\n",
    "# Standard Scaler\n",
    "dm.x_mean = np.mean(x_train)\n",
    "dm.x_std = np.std(x_train)\n",
    "dm.y_mean = np.mean(y_train)\n",
    "dm.y_std = np.std(y_train)\n",
    "# Min Max scaler\n",
    "dm.x_min = np.min(x_train)\n",
    "dm.x_max = np.max(x_train)\n",
    "if dm.scale_y_data:\n",
    "    dm.y_min = np.min(y_train)\n",
    "    dm.y_max = np.max(y_train)\n",
    "else:\n",
    "    dm.y_min = np.array(0, dtype=np.float32)\n",
    "    dm.y_max = np.array(1, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_min_max_scaler:\n",
    "    x_train = dm.min_max_scaler(x_train, dm.x_min, dm.x_max)\n",
    "    x_validation = dm.min_max_scaler(x_validation, dm.x_min, dm.x_max)\n",
    "    x_test = dm.min_max_scaler(x_test, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.min_max_scaler(y_train, dm.y_min, dm.y_max)\n",
    "        y_validation = dm.min_max_scaler(y_validation, dm.y_min, dm.y_max)\n",
    "        y_test = dm.min_max_scaler(y_test, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train = dm.standard_scaler(x_train, dm.x_mean, dm.x_std)\n",
    "    x_test = dm.standard_scaler(x_test, dm.x_mean, dm.x_std)\n",
    "    x_validation = dm.standard_scaler(x_validation, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train = dm.standard_scaler(y_train, dm.y_mean, dm.y_std)\n",
    "        y_validation = dm.standard_scaler(y_validation, dm.y_mean, dm.y_std)\n",
    "        y_test = dm.standard_scaler(y_test, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is logged in mlflow, create a new experiment\n",
    "experiment_name = (\n",
    "    name_of_this_run\n",
    "    + \"_\"\n",
    "    + \"MISO_MLP_\"\n",
    "    + input_parameters_name\n",
    "    + \"_\"\n",
    "    + output_parameters_name\n",
    ")\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an objective to be minimized\n",
    "\n",
    "\n",
    "def objective(params, experiment_id):\n",
    "    default_params = {\n",
    "        \"log_model\": True,\n",
    "        \"plot_diag\": True,\n",
    "        \"log_plot_type\": \"png\",\n",
    "        \"hidden_layer_sizes\": (100,),\n",
    "        \"activation\": \"relu\",\n",
    "        \"solver\": \"adam\",\n",
    "        \"alpha\": 0.0001,\n",
    "        \"batch_size\": \"auto\",\n",
    "        \"learning_rate_init\": 0.001,\n",
    "        \"max_iter\": 200,\n",
    "        \"shuffle\": True,\n",
    "        \"random_state\": None,\n",
    "        \"tol\": 0.001,\n",
    "        \"warm_start\": False,\n",
    "        \"early_stopping\": True,\n",
    "        \"validation_fraction\": 0.1,\n",
    "        \"beta_1\": 0.9,\n",
    "        \"beta_2\": 0.999,\n",
    "        \"epsilon\": 1e-08,\n",
    "        \"n_iter_no_change\": 20,\n",
    "        \"use_arrhenius_correction\": dm.use_arrhenius_correction,\n",
    "        \"use_arrhenius_correction_with_factor\": dm.use_arrhenius_correction_with_factor,\n",
    "        \"use_min_max_scaler\": dm.use_min_max_scaler,\n",
    "        \"use_standard_scaler\": dm.use_standard_scaler,\n",
    "        \"use_scale_y_data\": dm.scale_y_data,\n",
    "        \"x_mean\": dm.x_mean,\n",
    "        \"x_std\": dm.x_std,\n",
    "        \"y_mean\": dm.y_mean,\n",
    "        \"y_std\": dm.y_std,\n",
    "        \"x_min\": dm.x_min,\n",
    "        \"x_max\": dm.x_max,\n",
    "        \"y_min\": dm.y_min,\n",
    "        \"y_max\": dm.y_max,\n",
    "    }\n",
    "\n",
    "    default_params.update(params)\n",
    "    merged_params = default_params\n",
    "    dm.use_arrhenius_correction = merged_params[\"use_arrhenius_correction\"]\n",
    "    dm.use_arrhenius_correction_with_factor = merged_params[\n",
    "        \"use_arrhenius_correction_with_factor\"\n",
    "    ]\n",
    "    dm.use_min_max_scaler = merged_params[\"use_min_max_scaler\"]\n",
    "    dm.use_standard_scaler = merged_params[\"use_standard_scaler\"]\n",
    "    dm.scale_y_data = merged_params[\"use_scale_y_data\"]\n",
    "    dm.x_mean = merged_params[\"x_mean\"]\n",
    "    dm.x_std = merged_params[\"x_std\"]\n",
    "    dm.y_mean = merged_params[\"y_mean\"]\n",
    "    dm.y_std = merged_params[\"y_std\"]\n",
    "    dm.x_min = merged_params[\"x_min\"]\n",
    "    dm.x_max = merged_params[\"x_max\"]\n",
    "    dm.y_min = merged_params[\"y_min\"]\n",
    "    dm.y_max = merged_params[\"y_max\"]\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"MLP\"):\n",
    "        if merged_params[\"log_model\"]:\n",
    "            mlflow.sklearn.autolog()\n",
    "\n",
    "        mlflow.log_param(\"hidden_layer_sizes\", merged_params[\"hidden_layer_sizes\"])\n",
    "        mlflow.log_param(\"activation\", merged_params[\"activation\"])\n",
    "        mlflow.log_param(\"solver\", merged_params[\"solver\"])\n",
    "        mlflow.log_param(\"alpha\", merged_params[\"alpha\"])\n",
    "        mlflow.log_param(\"batch_size\", merged_params[\"batch_size\"])\n",
    "        mlflow.log_param(\"learning_rate_init\", merged_params[\"learning_rate_init\"])\n",
    "        mlflow.log_param(\"max_iter\", merged_params[\"max_iter\"])\n",
    "        mlflow.log_param(\"shuffle\", merged_params[\"shuffle\"])\n",
    "        mlflow.log_param(\"random_state\", merged_params[\"random_state\"])\n",
    "        mlflow.log_param(\"tol\", merged_params[\"tol\"])\n",
    "        mlflow.log_param(\"warm_start\", merged_params[\"warm_start\"])\n",
    "        mlflow.log_param(\"early_stopping\", merged_params[\"early_stopping\"])\n",
    "        mlflow.log_param(\"validation_fraction\", merged_params[\"validation_fraction\"])\n",
    "        mlflow.log_param(\"beta_1\", merged_params[\"beta_1\"])\n",
    "        mlflow.log_param(\"beta_2\", merged_params[\"beta_2\"])\n",
    "        mlflow.log_param(\"epsilon\", merged_params[\"epsilon\"])\n",
    "        mlflow.log_param(\"n_iter_no_change\", merged_params[\"n_iter_no_change\"])\n",
    "        mlflow.log_param(\"arrhenius_correction\", dm.use_arrhenius_correction)\n",
    "        mlflow.log_param(\n",
    "            \"arrhenius_correction_with_factor\", dm.use_arrhenius_correction_with_factor\n",
    "        )\n",
    "        mlflow.log_param(\"min_max_scaler\", dm.use_min_max_scaler)\n",
    "        mlflow.log_param(\"standard_scaler\", dm.use_standard_scaler)\n",
    "        mlflow.log_param(\"scale_y_data\", dm.scale_y_data)\n",
    "\n",
    "        model = MLPRegressor(\n",
    "            hidden_layer_sizes=merged_params[\"hidden_layer_sizes\"],\n",
    "            activation=merged_params[\"activation\"],\n",
    "            solver=merged_params[\"solver\"],\n",
    "            alpha=merged_params[\"alpha\"],\n",
    "            batch_size=merged_params[\"batch_size\"],\n",
    "            learning_rate_init=merged_params[\"learning_rate_init\"],\n",
    "            max_iter=merged_params[\"max_iter\"],\n",
    "            shuffle=merged_params[\"shuffle\"],\n",
    "            random_state=merged_params[\"random_state\"],\n",
    "            tol=merged_params[\"tol\"],\n",
    "            warm_start=merged_params[\"warm_start\"],\n",
    "            early_stopping=merged_params[\"early_stopping\"],\n",
    "            validation_fraction=merged_params[\"validation_fraction\"],\n",
    "            beta_1=merged_params[\"beta_1\"],\n",
    "            beta_2=merged_params[\"beta_2\"],\n",
    "            epsilon=merged_params[\"epsilon\"],\n",
    "            n_iter_no_change=merged_params[\"n_iter_no_change\"],\n",
    "        )\n",
    "\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        model.score(x_test, y_test.ravel())\n",
    "\n",
    "        train_maxae_temp = dm.evaluate_max_abs_error(model, x_train, y_train)\n",
    "        validation_maxae_temp = dm.evaluate_max_abs_error(\n",
    "            model, x_validation, y_validation\n",
    "        )\n",
    "        test_maxae_temp = dm.evaluate_max_abs_error(model, x_test, y_test)\n",
    "        train_mse_temp = dm.evaluate_mse(model, x_train, y_train)\n",
    "        validation_mse_temp = dm.evaluate_mse(model, x_validation, y_validation)\n",
    "        test_mse_temp = dm.evaluate_mse(model, x_test, y_test)\n",
    "        train_rmse_temp = dm.evaluate_rmse(model, x_train, y_train)\n",
    "        validation_rmse_temp = dm.evaluate_rmse(model, x_validation, y_validation)\n",
    "        test_rmse_temp = dm.evaluate_rmse(model, x_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"train_maxae_temp\", train_maxae_temp)\n",
    "        mlflow.log_metric(\"validation_maxae_temp\", validation_maxae_temp)\n",
    "        mlflow.log_metric(\"test_maxae_temp\", test_maxae_temp)\n",
    "        mlflow.log_metric(\"train_mse_temp\", train_mse_temp)\n",
    "        mlflow.log_metric(\"validation_mse_temp\", validation_mse_temp)\n",
    "        mlflow.log_metric(\"test_mse_temp\", test_mse_temp)\n",
    "        mlflow.log_metric(\"train_rmse_temp\", train_rmse_temp)\n",
    "        mlflow.log_metric(\"validation_rmse_temp\", validation_rmse_temp)\n",
    "        mlflow.log_metric(\"test_rmse_temp\", test_rmse_temp)\n",
    "\n",
    "        if merged_params[\"plot_diag\"]:\n",
    "            dm.plot_diag_during_fitting(\n",
    "                model,\n",
    "                name_of_this_run,\n",
    "                output_parameters,\n",
    "                x_test,\n",
    "                x_train,\n",
    "                x_validation,\n",
    "                data_set,\n",
    "                train_rmse_temp,\n",
    "                validation_rmse_temp,\n",
    "                test_rmse_temp,\n",
    "                merged_params,\n",
    "            )\n",
    "\n",
    "        mlflow.log_metric(\n",
    "            \"std_rmse\", np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"max_rmse\", np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "        )\n",
    "        mlflow.log_metric(\n",
    "            \"std_times_max_rmse\",\n",
    "            np.std([train_rmse_temp, validation_rmse_temp, test_rmse_temp])\n",
    "            * np.max([train_rmse_temp, validation_rmse_temp, test_rmse_temp]),\n",
    "        )\n",
    "\n",
    "        # fmin() minimizes the objective\n",
    "        weighted_fit_result = np.max(\n",
    "            [train_rmse_temp, validation_rmse_temp, test_rmse_temp]\n",
    "        )\n",
    "\n",
    "        mlflow.log_metric(\"weighted_fit_result\", weighted_fit_result)\n",
    "\n",
    "    return {\"loss\": weighted_fit_result, \"status\": hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temperature:\n",
    "    48, 20 -> 2.405839 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "\n",
    "search_space = hyperopt.hp.choice(\n",
    "    \"MLP\",\n",
    "    [\n",
    "        {\n",
    "            \"log_model\": hyperopt.hp.choice(\"log_model\", [True]),\n",
    "            \"plot_diag\": hyperopt.hp.choice(\"plot_diag\", [True]),\n",
    "            \"log_plot_type\": hyperopt.hp.choice(\"log_plot_type\", [\"svg\"]),\n",
    "            \"hidden_layer_sizes\": hyperopt.hp.choice(\n",
    "                \"hidden_layer_sizes\",\n",
    "                [\n",
    "                    (\n",
    "                        48,\n",
    "                        48,\n",
    "                    )\n",
    "                ],\n",
    "            ),\n",
    "            \"activation\": hyperopt.hp.choice(\"activation\", [\"relu\"]),\n",
    "            \"solver\": hyperopt.hp.choice(\"solver\", [\"adam\"]),\n",
    "            \"alpha\": hyperopt.hp.loguniform(\"alpha\", np.log(0.00000001), np.log(0.1)),\n",
    "            \"batch_size\": hyperopt.hp.choice(\"batch_size\", [\"auto\"]),\n",
    "            \"learning_rate_init\": hyperopt.hp.loguniform(\n",
    "                \"learning_rate_init\", np.log(0.0000001), np.log(10)\n",
    "            ),\n",
    "            \"max_iter\": hyperopt.hp.choice(\"max_iter\", [10000]),\n",
    "            \"shuffle\": hyperopt.hp.choice(\"shuffle\", [True]),\n",
    "            \"random_state\": hyperopt.hp.choice(\"random_state\", [None]),\n",
    "            \"tol\": hyperopt.hp.loguniform(\"tol\", np.log(0.0000000001), np.log(0.0001)),\n",
    "            \"warm_start\": hyperopt.hp.choice(\"warm_start\", [False]),\n",
    "            \"early_stopping\": hyperopt.hp.choice(\"early_stopping\", [True]),\n",
    "            \"validation_fraction\": hyperopt.hp.choice(\"validation_fraction\", [0.1]),\n",
    "            \"beta_1\": hyperopt.hp.loguniform(\"beta_1\", np.log(1e-3), np.log(1)),\n",
    "            \"beta_2\": hyperopt.hp.loguniform(\"beta_2\", np.log(1e-3), np.log(1)),\n",
    "            \"epsilon\": hyperopt.hp.loguniform(\"epsilon\", np.log(1e-12), np.log(1e-04)),\n",
    "            \"n_iter_no_change\": hyperopt.hp.choice(\"n_iter_no_change\", [20]),\n",
    "            \"use_arrhenius_correction\": hyperopt.hp.choice(\n",
    "                \"use_arrhenius_correction\", [dm.use_arrhenius_correction]\n",
    "            ),\n",
    "            \"use_arrhenius_correction_with_factor\": hyperopt.hp.choice(\n",
    "                \"use_arrhenius_correction_with_factor\",\n",
    "                [dm.use_arrhenius_correction_with_factor],\n",
    "            ),\n",
    "            \"use_min_max_scaler\": hyperopt.hp.choice(\n",
    "                \"use_min_max_scaler\", [dm.use_min_max_scaler]\n",
    "            ),\n",
    "            \"use_standard_scaler\": hyperopt.hp.choice(\n",
    "                \"use_standard_scaler\", [dm.use_standard_scaler]\n",
    "            ),\n",
    "            \"use_scale_y_data\": hyperopt.hp.choice(\n",
    "                \"use_scale_y_data\", [dm.scale_y_data]\n",
    "            ),\n",
    "            \"x_mean\": hyperopt.hp.choice(\"x_mean\", [dm.x_mean]),\n",
    "            \"x_std\": hyperopt.hp.choice(\"x_std\", [dm.x_std]),\n",
    "            \"y_mean\": hyperopt.hp.choice(\"y_mean\", [dm.y_mean]),\n",
    "            \"y_std\": hyperopt.hp.choice(\"y_std\", [dm.y_std]),\n",
    "            \"x_min\": hyperopt.hp.choice(\"x_min\", [dm.x_min]),\n",
    "            \"x_max\": hyperopt.hp.choice(\"x_max\", [dm.x_max]),\n",
    "            \"y_min\": hyperopt.hp.choice(\"y_min\", [dm.y_min]),\n",
    "            \"y_max\": hyperopt.hp.choice(\"y_max\", [dm.y_max]),\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an optimization type\n",
    "\n",
    "# algo=hyperopt.tpe.suggest\n",
    "algo = hyperopt.rand.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model, you can track it in mlflow: [http://127.0.0.1:1234](http://127.0.0.1:1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timout_in_minutes = 24 * 60\n",
    "max_evals = 10\n",
    "\n",
    "# if java is installed (only recommended under linux or wsl)\n",
    "# import pyspark\n",
    "# spark_trails = hyperopt.SparkTrials(parallelism=16)\n",
    "# best_result = hyperopt.fmin(\n",
    "#     fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "#     space=search_space,\n",
    "#     algo=algo,\n",
    "#     max_evals=max_evals,\n",
    "#     timeout=timout_in_minutes * 60,\n",
    "#     trials=spark_trails,\n",
    "# )\n",
    "# if java is not available\n",
    "best_result = hyperopt.fmin(\n",
    "    fn=partial(objective, experiment_id=mlflow_exp.experiment_id),\n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=max_evals,\n",
    "    timeout=timout_in_minutes * 60,\n",
    ")\n",
    "\n",
    "print(hyperopt.space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the best Model and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run_eval = name_of_this_run\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run_eval + \".parquet\"\n",
    "df_eval = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change if needed\n",
    "input_parameters_eval = input_parameters\n",
    "input_parameters_name_eval = input_parameters_name\n",
    "output_parameters_eval = output_parameters\n",
    "output_parameters_name_eval = output_parameters_name\n",
    "\n",
    "test_labels_eval = test_labels\n",
    "output_intervals_for_test_eval = output_intervals_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set_eval = dm.get_set(\n",
    "    df_eval,\n",
    "    output_parameters_eval,\n",
    "    feature_keys=input_parameters_eval,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=output_intervals_for_test_eval,\n",
    "    label_for_test_intervals=test_labels_eval,\n",
    "    label_name=output_parameters_name_eval,\n",
    ")\n",
    "x_train_eval, y_train_eval = data_set_eval[\"train\"]\n",
    "x_validation_eval, y_validation_eval = data_set_eval[\"validation\"]\n",
    "x_test_eval, y_test_eval = data_set_eval[\"test\"]\n",
    "\n",
    "x_train_eval = np.float32(x_train_eval)\n",
    "y_train_eval = np.float32(y_train_eval)\n",
    "x_validation_eval = np.float32(x_validation_eval)\n",
    "y_validation_eval = np.float32(y_validation_eval)\n",
    "x_test_eval = np.float32(x_test_eval)\n",
    "y_test_eval = np.float32(y_test_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dm.use_arrhenius_correction:\n",
    "    x_train_eval = dm.arrhenius_correction(x_train_eval)\n",
    "    x_validation_eval = dm.arrhenius_correction(x_validation_eval)\n",
    "    x_test_eval = dm.arrhenius_correction(x_test_eval)\n",
    "\n",
    "if dm.use_min_max_scaler:\n",
    "    x_train_eval = dm.min_max_scaler(x_train_eval, dm.x_min, dm.x_max)\n",
    "    x_validation_eval = dm.min_max_scaler(x_validation_eval, dm.x_min, dm.x_max)\n",
    "    x_test_eval = dm.min_max_scaler(x_test_eval, dm.x_min, dm.x_max)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_eval = dm.min_max_scaler(y_validation_eval, dm.y_min, dm.y_max)\n",
    "        y_test_eval = dm.min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "elif dm.use_standard_scaler:\n",
    "    x_train_eval = dm.standard_scaler(x_train_eval, dm.x_mean, dm.x_std)\n",
    "    x_test_eval = dm.standard_scaler(x_test_eval, dm.x_mean, dm.x_std)\n",
    "    x_validation_eval = dm.standard_scaler(x_validation_eval, dm.x_mean, dm.x_std)\n",
    "    if dm.scale_y_data:\n",
    "        y_train_eval = dm.standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_eval = dm.standard_scaler(y_validation_eval, dm.y_mean, dm.y_std)\n",
    "        y_test_eval = dm.standard_scaler(y_test_eval, dm.y_mean, dm.y_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [http://127.0.0.1:1234](http://127.0.0.1:1234) to select a fitted model. If you click on it, you can extract the run ID. It could look like this: \"ad26474e8c324f84906c9fc501928cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose a specific model\n",
    "# logged_model = 'ad26474e8c324f84906c9fc501928cae'\n",
    "# or just load the best model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "    order_by=[\"metrics.max_rmse\"],\n",
    "    max_results=1,\n",
    ")\n",
    "logged_model = runs[0].info.run_id\n",
    "\n",
    "# Load model as a Sklearn.\n",
    "run_eval = mlflow.get_run(logged_model)\n",
    "loaded_model = mlflow.sklearn.load_model(run_eval.info.artifact_uri + \"/model/\")\n",
    "\n",
    "train_rmse_temp = dm.evaluate_rmse(loaded_model, x_train_eval, y_train_eval)\n",
    "print(\"Train RMSE: \" + str(train_rmse_temp))\n",
    "validation_rmse_temp = dm.evaluate_rmse(\n",
    "    loaded_model, x_validation_eval, y_validation_eval\n",
    ")\n",
    "print(\"Validation RMSE: \" + str(validation_rmse_temp))\n",
    "test_rmse_temp = dm.evaluate_rmse(loaded_model, x_test_eval, y_test_eval)\n",
    "print(\"Test RMSE: \" + str(test_rmse_temp))\n",
    "\n",
    "unique_model_name = (\n",
    "    experiment_name\n",
    "    + \"_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \"_\"\n",
    "    + logged_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * eisplot.cm, 10 * eisplot.cm))\n",
    "\n",
    "cell_list_train = list(set(data_set_eval[\"df_train\"].index.get_level_values(0)))\n",
    "y_pred_train_eval = loaded_model.predict(x_train_eval)\n",
    "y_pred_train_eval = y_pred_train_eval.ravel()\n",
    "\n",
    "cell_list_validation = list(\n",
    "    set(data_set_eval[\"df_validation\"].index.get_level_values(0))\n",
    ")\n",
    "y_pred_validation_eval = loaded_model.predict(x_validation_eval)\n",
    "y_pred_validation_eval = y_pred_validation_eval.ravel()\n",
    "\n",
    "cell_list_test = list(set(data_set_eval[\"df_test\"].index.get_level_values(0)))\n",
    "y_pred_test_eval = loaded_model.predict(x_test_eval)\n",
    "y_pred_test_eval = y_pred_test_eval.ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        y_pred_train_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_train_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_min_max_scaler(\n",
    "            y_pred_test_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_train_plot = dm.inverse_min_max_scaler(y_train_eval, dm.y_min, dm.y_max)\n",
    "        y_validation_plot = dm.inverse_min_max_scaler(\n",
    "            y_validation_eval, dm.y_min, dm.y_max\n",
    "        )\n",
    "        y_test_plot = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        y_pred_train_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_train_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_validation_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_pred_test_eval = dm.inverse_standard_scaler(\n",
    "            y_pred_test_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_train_plot = dm.inverse_standard_scaler(y_train_eval, dm.y_mean, dm.y_std)\n",
    "        y_validation_plot = dm.inverse_standard_scaler(\n",
    "            y_validation_eval, dm.y_mean, dm.y_std\n",
    "        )\n",
    "        y_test_plot = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_train_plot = y_train_eval\n",
    "    y_validation_plot = y_validation_eval\n",
    "    y_test_plot = y_test_eval\n",
    "\n",
    "fig, ax = eisplot.setup_scatter(\n",
    "    data_set,\n",
    "    test_rmse_temp,\n",
    "    title=False,\n",
    "    legend=False,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    ax_xlabel=False,\n",
    "    ax_ylabel=False,\n",
    "    subplots_adjust=True,\n",
    "    add_trendline=True,\n",
    "    label=\"\",\n",
    ")\n",
    "ax.plot(\n",
    "    y_train_plot,\n",
    "    y_pred_train_eval,\n",
    "    \".\",\n",
    "    color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_validation_plot,\n",
    "    y_pred_validation_eval,\n",
    "    \"1\",\n",
    "    color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "ax.plot(\n",
    "    y_test_plot,\n",
    "    y_pred_test_eval,\n",
    "    \"2\",\n",
    "    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    alpha=0.5,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"actual: Output\")\n",
    "ax.set_ylabel(\"predicted: Output\")\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0], [0], color=eisplot.rwth_colors.colors[(\"green\", 100)], label=\"ideal\"\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\".\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"1\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"2\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert, Export, Test and Validate with ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_type = [(\"float_input\", FloatTensorType([None, len(x_train[0])]))]\n",
    "onnx_filename = \"microcontroller_eis_network/onnx_export/\" + unique_model_name + \".onnx\"\n",
    "onx = convert_sklearn(loaded_model, initial_types=input_type)\n",
    "with open(onnx_filename, \"wb\") as f:\n",
    "    f.write(onx.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = rt.InferenceSession(onnx_filename, providers=[\"CPUExecutionProvider\"])\n",
    "input_name = sess.get_inputs()[0].name\n",
    "label_name = sess.get_outputs()[0].name\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval})[0]\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "        y_test_eval_ref = dm.inverse_min_max_scaler(y_test_eval, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "        y_test_eval_ref = dm.inverse_standard_scaler(y_test_eval, dm.y_mean, dm.y_std)\n",
    "else:\n",
    "    y_test_eval_ref = y_test_eval.copy()\n",
    "\n",
    "diff = pred_onx.ravel() - y_test_eval_ref.ravel()\n",
    "print(np.max(np.abs(diff)))\n",
    "print(np.mean(diff))\n",
    "print(np.std(diff))\n",
    "print(np.sqrt(np.mean((diff) ** 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_eval_float32 = x_test_eval.astype(np.float32)\n",
    "\n",
    "pred_sklearn = loaded_model.predict(x_test_eval_float32)\n",
    "pred_onx = sess.run([label_name], {input_name: x_test_eval_float32})[0].ravel()\n",
    "\n",
    "if dm.scale_y_data:\n",
    "    if dm.use_min_max_scaler:\n",
    "        pred_sklearn = dm.inverse_min_max_scaler(pred_sklearn, dm.y_min, dm.y_max)\n",
    "        pred_onx = dm.inverse_min_max_scaler(pred_onx, dm.y_min, dm.y_max)\n",
    "    elif dm.use_standard_scaler:\n",
    "        pred_sklearn = dm.inverse_standard_scaler(pred_sklearn, dm.y_mean, dm.y_std)\n",
    "        pred_onx = dm.inverse_standard_scaler(pred_onx, dm.y_mean, dm.y_std)\n",
    "\n",
    "diff = pred_sklearn.ravel() - pred_onx.ravel()\n",
    "print(\"Max difference between scikit-learn and ONNX predictions:\", np.max(np.abs(diff)))\n",
    "print(\"Mean difference between scikit-learn and ONNX predictions:\", np.mean(diff))\n",
    "print(\"RMSE of differences:\", np.sqrt(np.mean(diff**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the test data for the microcontroller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_path = \"microcontroller_eis_network/Core/Inc/\"\n",
    "dm.create_test_header_file(data_set_eval, header_path, unique_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further comparison of different fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()\n",
    "experiment_id = mlflow_exp.experiment_id\n",
    "experiment_id\n",
    "\n",
    "for exp in mlflow.search_experiments():\n",
    "    if exp.experiment_id == experiment_id:\n",
    "        experiment_tmp = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "        experiment_list = pd.concat([experiment_list, experiment_tmp])\n",
    "\n",
    "experiment_list = experiment_list.reset_index(drop=True)\n",
    "experiment_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_values = [\n",
    "    experiment_list[\"metrics.train_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.test_maxae_temp\"].values,\n",
    "    experiment_list[\"metrics.train_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.train_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_rmse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_rmse_temp\"].values,\n",
    "    experiment_list[\"params.hidden_layer_sizes\"].values,\n",
    "    experiment_list[\"params.activation\"].values,\n",
    "    experiment_list[\"params.solver\"].values,\n",
    "    experiment_list[\"params.alpha\"].values,\n",
    "    experiment_list[\"params.batch_size\"].values,\n",
    "    experiment_list[\"params.learning_rate_init\"].values,\n",
    "    experiment_list[\"params.max_iter\"].values,\n",
    "    experiment_list[\"params.tol\"].values,\n",
    "    experiment_list[\"params.beta_1\"].values,\n",
    "    experiment_list[\"params.beta_2\"].values,\n",
    "    experiment_list[\"params.epsilon\"].values,\n",
    "    experiment_list[\"params.n_iter_no_change\"].values,\n",
    "]\n",
    "df_experiment = pd.DataFrame(\n",
    "    np.transpose(scatter_values),\n",
    "    columns=[\n",
    "        \"Train MAXAE in K\",\n",
    "        \"Validation MAXAE in K\",\n",
    "        \"Test MAXAE in K\",\n",
    "        \"Train MSE in K^2\",\n",
    "        \"Validation MSE in K^2\",\n",
    "        \"Test MSE in K^2\",\n",
    "        \"Train RMSE in K\",\n",
    "        \"Validation RMSE in K\",\n",
    "        \"Test RMSE in K\",\n",
    "        \"Hidden Layer Sizes\",\n",
    "        \"Activation\",\n",
    "        \"Solver\",\n",
    "        \"Alpha\",\n",
    "        \"Batch Size\",\n",
    "        \"Learning Rate Init\",\n",
    "        \"Max Iter\",\n",
    "        \"Tol\",\n",
    "        \"Beta 1\",\n",
    "        \"Beta 2\",\n",
    "        \"Epsilon\",\n",
    "        \"N Iter No Change\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit the error if necessary\n",
    "df_experiment[df_experiment[\"Test RMSE in K\"] > 10] = np.nan\n",
    "df_experiment = df_experiment.dropna(subset=[\"Test RMSE in K\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_experiment.drop(\n",
    "    columns=[\"Hidden Layer Sizes\", \"Activation\", \"Solver\", \"Batch Size\"]\n",
    ").corr()\n",
    "corr.style.background_gradient(cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(unique_model_name)\n",
    "except:\n",
    "    unique_model_name = (\n",
    "        experiment_name\n",
    "        + \"_\"\n",
    "        + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filepath = r\"./mlruns/\" + unique_model_name + \".parquet\"\n",
    "experiment_list.to_parquet(destination_filepath, compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(18 * eisplot.cm, 12 * eisplot.cm), sharex=True)\n",
    "\n",
    "variables = [\"Alpha\", \"Tol\", \"Beta 1\", \"Beta 2\", \"Epsilon\", \"Learning Rate Init\"]\n",
    "\n",
    "for variable_idx, variable in enumerate(variables):\n",
    "    plot_column = np.floor(variable_idx / 2).astype(\"int\")\n",
    "    plot_row = variable_idx - 2 * plot_column\n",
    "\n",
    "    concave_hull_ratio = 0.25\n",
    "\n",
    "    min_error = np.min(\n",
    "        [\n",
    "            df_experiment[\"Train RMSE in K\"].values,\n",
    "            df_experiment[\"Validation RMSE in K\"].values,\n",
    "            df_experiment[\"Test RMSE in K\"].values,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Train RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T.astype(np.float64)\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Train RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Validation RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T.astype(np.float64)\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Validation RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment[\"Test RMSE in K\"].values, df_experiment[variable].values)\n",
    "    ).T.astype(np.float64)\n",
    "    axs[plot_column, plot_row].scatter(\n",
    "        df_experiment[\"Test RMSE in K\"].values,\n",
    "        df_experiment[variable].values,\n",
    "        c=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        alpha=0.1,\n",
    "        marker=\".\",\n",
    "    )\n",
    "    # points_hull = np.exp(\n",
    "    #     np.array(\n",
    "    #         shapely.concave_hull(\n",
    "    #             shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "    #         ).exterior.coords\n",
    "    #     )\n",
    "    # )\n",
    "    # axs[plot_column, plot_row].fill(\n",
    "    #     points_hull[:, 0],\n",
    "    #     points_hull[:, 1],\n",
    "    #     color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "    #     alpha=0.5,\n",
    "    # )\n",
    "\n",
    "    axs[plot_column, plot_row].set_ylabel(variable)\n",
    "    axs[plot_column, plot_row].set_yscale(\"linear\")\n",
    "    axs[plot_column, plot_row].set_xscale(\"log\")\n",
    "    axs[plot_column, plot_row].grid()\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\":\",\n",
    "        color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    "        label=\"selected value\",\n",
    "        alpha=1.0,\n",
    "    ),\n",
    "]\n",
    "fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper center\",\n",
    "    scatterpoints=1,\n",
    "    ncol=4,\n",
    ")\n",
    "\n",
    "\n",
    "axs[2, 0].set_xlabel(\"RMSE in K\")\n",
    "axs[2, 1].set_xlabel(\"RMSE in K\")\n",
    "fig.tight_layout()\n",
    "\n",
    "x_values = np.array(axs[0, 0].get_xlim()) * 0.95\n",
    "\n",
    "axs[0, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"alpha\"]), float(run_eval.data.params[\"alpha\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[0, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"tol\"]), float(run_eval.data.params[\"tol\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"beta_1\"]), float(run_eval.data.params[\"beta_1\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 1].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"beta_2\"]), float(run_eval.data.params[\"beta_2\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[2, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"epsilon\"]), float(run_eval.data.params[\"epsilon\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[2, 1].plot(\n",
    "    x_values,\n",
    "    [\n",
    "        float(run_eval.data.params[\"learning_rate_init\"]),\n",
    "        float(run_eval.data.params[\"learning_rate_init\"]),\n",
    "    ],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
