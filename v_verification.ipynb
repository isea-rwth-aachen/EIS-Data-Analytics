{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification of Fitting Regression Models\n",
    "Bandwidth of Frequencies (Multiple Input - Single Output)  \n",
    "This notebook is optimized for SOH estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In order to see the results you should start the MLflow ui seperately**:\n",
    "1. Open a promt/terminal and navigate to the path of this project\n",
    "2. Activate the virtual environment:  \n",
    "    (Windows: ```.venv\\eis_data_analytics\\Scripts\\activate```,  \n",
    "    Linux/Mac: ```.venv/eis_data_analytics/bin/activate```)\n",
    "3. Now start MLflow with ```mlflow server --port 1234``` consider to add e.g.: ```--workers=16 --gunicorn-opts='--timeout 600'```\n",
    "4. Open [http://127.0.0.1:1234](http://127.0.0.1:1234) in your browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget \n",
    "\n",
    "from modules import data_preparation as dp\n",
    "from modules import dataset_manipulation as dm\n",
    "from modules import eisplot as eisplot\n",
    "from modules.eisplot import plt\n",
    "from modules.eisplot import mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from functools import partial\n",
    "import hyperopt\n",
    "import mlflow\n",
    "import shapely\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "cm = 1 / 2.54  # centimeters in inches\n",
    "\n",
    "## if you have installed latex and want to use it for plots, uncomment the following 3 lines\n",
    "# eisplot.mpl.rcParams.update({\"text.usetex\": True,'savefig.format':'pdf'})\n",
    "# eisplot.mpl.rc('font', **{'family': 'serif', 'serif': ['Computer Modern']})\n",
    "# eisplot.mpl.rc('text.latex', preamble=r'\\usepackage{underscore}')\n",
    "\n",
    "## safe figures e.g. with:\n",
    "# plot_name = \"custom_3D_plot\"\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "# plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run = \"reference_data\"\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run + \".parquet\"\n",
    "df = pd.read_parquet(destination_filepath)\n",
    "destination_filepath = r\"./data/key_lookup/key_lookup_\" + name_of_this_run + \".parquet\"\n",
    "key_lookup_df = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_the_feature = \"_abs\"\n",
    "# name_of_the_feature = \"_abs_temp_soc\"\n",
    "# name_of_the_feature = \"_abs_phase_temp_soc\"\n",
    "\n",
    "feature_selection = dm.json_2_list(name_of_this_run + name_of_the_feature + \".json\")\n",
    "print(feature_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Output Parameter of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameter = \"SOH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = (\n",
    "    name_of_this_run + \"_\" + \"SVR_MISO_Random_\" + output_parameter + name_of_the_feature\n",
    ")\n",
    "mlflow_exp = mlflow.set_experiment(experiment_name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define if Arrenhius prescaling should be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrhenius_correction(value):\n",
    "    return np.log(1 / value)\n",
    "\n",
    "\n",
    "def arrhenius_correction_inverse(value):\n",
    "    return 1 / np.exp(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[arrhenius_correction_inverse(arrhenius_correction(i)) for i in [0.01, 0.1, 1, 10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we directly modify the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[key_lookup_df[\"EIS_Z_abs\"].to_list()] = arrhenius_correction(\n",
    "    df[key_lookup_df[\"EIS_Z_abs\"].to_list()].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to Training Data and define Calculation of Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split 20 / 80 % into validation and train data. As 150 is out of the value range the test set is just empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to training arrays\n",
    "data_set = dm.get_set(\n",
    "    df,\n",
    "    output_parameter,\n",
    "    feature_keys=feature_selection,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=[[150, 151]],\n",
    ")\n",
    "x_train, y_train = data_set[\"train\"]\n",
    "x_validation, y_validation = data_set[\"validation\"]\n",
    "x_test, y_test = data_set[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = MinMaxScaler()\n",
    "transformer = transformer.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mse_svr(model, x, y):\n",
    "    y_pred = model.predict(x)\n",
    "    y_orig = y\n",
    "    mse = ((y_pred - y_orig) ** 2).mean()\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Hyperparameter optimization the fmin of hyperopt is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an objective to be minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_objective(params, experiment_id):\n",
    "    \"\"\"\n",
    "    Optimize the SVM model using SVR.\n",
    "\n",
    "    Parameters:\n",
    "        params (dict): The parameters for the SVM model and the validation.\n",
    "        experiment_id: The id of the mlflow experiment.\n",
    "\n",
    "    Returns:\n",
    "        dict: The loss and status of the optimization.\n",
    "    \"\"\"\n",
    "\n",
    "    default_params = {\n",
    "        \"log_model\": False,\n",
    "        \"plot_diag\": False,\n",
    "        \"log_plot_type\": \"png\",\n",
    "        \"kernel\": \"rbf\",\n",
    "        \"epsilon\": 0.1,\n",
    "        \"C\": 1,\n",
    "        \"tol\": 0.001,\n",
    "        \"coef0\": 0.0,\n",
    "        \"gamma\": \"auto\",\n",
    "        \"degree\": 3,\n",
    "    }\n",
    "\n",
    "    default_params.update(params)\n",
    "    merged_params = default_params\n",
    "\n",
    "    apply_test = False\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id, run_name=\"SVR\"):\n",
    "        if merged_params[\"log_model\"]:\n",
    "            mlflow.sklearn.autolog()\n",
    "\n",
    "        mlflow.log_param(\"kernel\", merged_params[\"kernel\"])\n",
    "        mlflow.log_param(\"C\", merged_params[\"C\"])\n",
    "        mlflow.log_param(\"tol\", merged_params[\"tol\"])\n",
    "        mlflow.log_param(\"gamma\", merged_params[\"gamma\"])\n",
    "        mlflow.log_param(\"epsilon\", merged_params[\"epsilon\"])\n",
    "        mlflow.log_param(\"degree\", merged_params[\"degree\"])\n",
    "        mlflow.log_param(\"coef0\", merged_params[\"coef0\"])\n",
    "\n",
    "        pipeline = Pipeline(\n",
    "            steps=[\n",
    "                (\"scaler\", transformer),\n",
    "                (\n",
    "                    \"svm\",\n",
    "                    SVR(\n",
    "                        kernel=merged_params[\"kernel\"],\n",
    "                        C=merged_params[\"C\"],\n",
    "                        tol=merged_params[\"tol\"],\n",
    "                        gamma=merged_params[\"gamma\"],\n",
    "                        epsilon=merged_params[\"epsilon\"],\n",
    "                        degree=merged_params[\"degree\"],\n",
    "                        coef0=merged_params[\"coef0\"],\n",
    "                        cache_size=4000,\n",
    "                    ),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        pipeline.fit(x_train, y_train)\n",
    "        pipeline.score(x_validation, y_validation)\n",
    "\n",
    "        train_mse_temp = evaluate_mse_svr(pipeline, x_train, y_train)\n",
    "        validation_mse_temp = evaluate_mse_svr(pipeline, x_validation, y_validation)\n",
    "        if apply_test:\n",
    "            test_mse_temp = evaluate_mse_svr(pipeline, x_test, y_test)\n",
    "\n",
    "        mlflow.log_metric(\"train_mse_temp\", train_mse_temp)\n",
    "        mlflow.log_metric(\"validation_mse_temp\", validation_mse_temp)\n",
    "        if apply_test:\n",
    "            mlflow.log_metric(\"test_mse_temp\", test_mse_temp)\n",
    "\n",
    "        if merged_params[\"plot_diag\"]:\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(7 * cm, 7 * cm))\n",
    "            plt.cla()\n",
    "\n",
    "            # prediction on train set\n",
    "            y_pred = pipeline.predict(x_train)\n",
    "            cell_list = list(set(data_set[\"df_train\"].index.get_level_values(0)))\n",
    "            fig, ax = eisplot.cell_scatter(\n",
    "                data_set,\n",
    "                y_pred,\n",
    "                cell_names=cell_list,\n",
    "                title=False,\n",
    "                legend=False,\n",
    "                fig=fig,\n",
    "                ax=ax,\n",
    "            )\n",
    "\n",
    "            # prediction on validation set\n",
    "            y_pred = pipeline.predict(x_validation)\n",
    "            cell_list = list(set(data_set[\"df_validation\"].index.get_level_values(0)))\n",
    "            fig, ax = eisplot.cell_scatter(\n",
    "                data_set,\n",
    "                y_pred,\n",
    "                is_validation=True,\n",
    "                cell_names=cell_list,\n",
    "                title=False,\n",
    "                legend=False,\n",
    "                fig=fig,\n",
    "                ax=ax,\n",
    "                add_trendline=False,\n",
    "            )\n",
    "\n",
    "            if apply_test:\n",
    "                # prediction on test set\n",
    "                y_pred = pipeline.predict(x_test)\n",
    "                cell_list = list(set(data_set[\"df_test\"].index.get_level_values(0)))\n",
    "                fig, ax = eisplot.cell_scatter(\n",
    "                    data_set,\n",
    "                    y_pred,\n",
    "                    is_test=True,\n",
    "                    cell_names=cell_list,\n",
    "                    title=False,\n",
    "                    legend=False,\n",
    "                    fig=fig,\n",
    "                    ax=ax,\n",
    "                    add_trendline=False,\n",
    "                )\n",
    "\n",
    "            if (name_of_this_run == \"example_data\") & (\n",
    "                output_parameter == \"Temperature\"\n",
    "            ):\n",
    "                ax.set_xlim([-30, 60])\n",
    "                ax.set_ylim([-30, 60])\n",
    "\n",
    "                ax.text(\n",
    "                    -4,\n",
    "                    -19,\n",
    "                    \"Train MSE: \" + \"%.2f\" % train_mse_temp + \" K\",\n",
    "                    horizontalalignment=\"left\",\n",
    "                    verticalalignment=\"center\",\n",
    "                    fontsize=8,\n",
    "                )\n",
    "                ax.text(\n",
    "                    -4,\n",
    "                    -23,\n",
    "                    \"Validation MSE: \" + \"%.2f\" % validation_mse_temp + \" K\",\n",
    "                    horizontalalignment=\"left\",\n",
    "                    verticalalignment=\"center\",\n",
    "                    fontsize=8,\n",
    "                )\n",
    "                if apply_test:\n",
    "                    ax.text(\n",
    "                        -4,\n",
    "                        -27,\n",
    "                        \"Test MSE: \" + \"%.2f\" % test_mse_temp + \" K\",\n",
    "                        horizontalalignment=\"left\",\n",
    "                        verticalalignment=\"center\",\n",
    "                        fontsize=8,\n",
    "                    )\n",
    "\n",
    "            legend_elements = [\n",
    "                mpl.lines.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    color=eisplot.rwth_colors.colors[(\"green\", 100)],\n",
    "                    label=\"ideal\",\n",
    "                ),\n",
    "                mpl.lines.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\".\",\n",
    "                    color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "                    linestyle=\"\",\n",
    "                    label=\"train\",\n",
    "                    alpha=0.5,\n",
    "                ),\n",
    "                mpl.lines.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\"2\",\n",
    "                    color=eisplot.rwth_colors.colors[(\"orange\", 100)],\n",
    "                    linestyle=\"\",\n",
    "                    label=\"validation\",\n",
    "                    alpha=0.5,\n",
    "                ),\n",
    "                mpl.lines.Line2D(\n",
    "                    [0],\n",
    "                    [0],\n",
    "                    marker=\"1\",\n",
    "                    color=eisplot.rwth_colors.colors[(\"lavender\", 100)],\n",
    "                    linestyle=\"\",\n",
    "                    label=\"test\",\n",
    "                    alpha=0.5,\n",
    "                ),\n",
    "            ]\n",
    "            if apply_test:\n",
    "                ax.legend(\n",
    "                    handles=legend_elements,\n",
    "                    loc=\"best\",\n",
    "                    scatterpoints=1,\n",
    "                    prop={\"size\": 8},\n",
    "                )\n",
    "            else:\n",
    "                ax.legend(\n",
    "                    handles=legend_elements[:-1],\n",
    "                    loc=\"best\",\n",
    "                    scatterpoints=1,\n",
    "                    prop={\"size\": 8},\n",
    "                )\n",
    "            fig.subplots_adjust(bottom=0.14, left=0.19)\n",
    "            mlflow.log_figure(\n",
    "                fig, \"prediction_vs_actual.\" + merged_params[\"log_plot_type\"]\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "        mlflow.log_metric(\"support_vectors\", pipeline.named_steps[\"svm\"].n_support_)\n",
    "        mlflow.log_metric(\n",
    "            \"support_vectors_percent\",\n",
    "            pipeline.named_steps[\"svm\"].n_support_ / x_train.shape[0],\n",
    "        )\n",
    "        if apply_test:\n",
    "            mlflow.log_metric(\n",
    "                \"std_mse\", np.std([train_mse_temp, validation_mse_temp, test_mse_temp])\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"max_mse\", np.max([train_mse_temp, validation_mse_temp, test_mse_temp])\n",
    "            )\n",
    "            mlflow.log_metric(\n",
    "                \"std_times_max_mse\",\n",
    "                np.std([train_mse_temp, validation_mse_temp, test_mse_temp])\n",
    "                * np.max([train_mse_temp, validation_mse_temp, test_mse_temp]),\n",
    "            )\n",
    "        else:\n",
    "            mlflow.log_metric(\"std_mse\", np.std([train_mse_temp, validation_mse_temp]))\n",
    "            mlflow.log_metric(\"max_mse\", np.max([train_mse_temp, validation_mse_temp]))\n",
    "            mlflow.log_metric(\n",
    "                \"std_times_max_mse\",\n",
    "                np.std([train_mse_temp, validation_mse_temp])\n",
    "                * np.max([train_mse_temp, validation_mse_temp]),\n",
    "            )\n",
    "\n",
    "        # fmin() minimizes the objective\n",
    "        if apply_test:\n",
    "            weighted_fit_result = np.max(\n",
    "                [train_mse_temp, validation_mse_temp, test_mse_temp]\n",
    "            )\n",
    "        else:\n",
    "            weighted_fit_result = np.max([train_mse_temp, validation_mse_temp])\n",
    "\n",
    "    return {\"loss\": weighted_fit_result, \"status\": hyperopt.STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_space = hyperopt.hp.choice('SVM', [\n",
    "#     {\n",
    "#         'log_model': hyperopt.hp.choice('log_model', [True]),\n",
    "#         'plot_diag': hyperopt.hp.choice('plot_diag', [True]),\n",
    "#         'log_plot_type': hyperopt.hp.choice('log_plot_type', ['svg']),\n",
    "#         'gamma': hyperopt.hp.choice('gamma', ['scale']),\n",
    "#         'tol': hyperopt.hp.choice('tol', [0.001]),\n",
    "#         'C': hyperopt.hp.choice('C', [0.01, 0.1, 1, 10, 100, 1000]),\n",
    "#         'epsilon': hyperopt.hp.choice('epsilon', [0.1]),\n",
    "#         'degree': hyperopt.hp.choice('degree', [3, 4, 5]),\n",
    "#         'coef0': hyperopt.hp.choice('coef0', [0.0]),\n",
    "#         'kernel': hyperopt.hp.choice('kernel', ['rbf','linear','poly']),\n",
    "#     }\n",
    "# ])\n",
    "\n",
    "search_space = hyperopt.hp.choice(\n",
    "    \"SVM\",\n",
    "    [\n",
    "        {\n",
    "            \"log_model\": hyperopt.hp.choice(\"log_model\", [True]),\n",
    "            \"plot_diag\": hyperopt.hp.choice(\"plot_diag\", [True]),\n",
    "            \"log_plot_type\": hyperopt.hp.choice(\"log_plot_type\", [\"svg\"]),\n",
    "            \"gamma\": hyperopt.hp.loguniform(\"gamma\", np.log(0.001), np.log(100)),\n",
    "            \"tol\": hyperopt.hp.loguniform(\"tol\", np.log(0.001), np.log(10)),\n",
    "            \"C\": hyperopt.hp.loguniform(\"C\", np.log(0.01), np.log(10000000000)),\n",
    "            \"epsilon\": hyperopt.hp.loguniform(\"epsilon\", np.log(0.01), np.log(10)),\n",
    "            \"kernel\": hyperopt.hp.choice(\"kernel\", [\"rbf\"]),\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an optimization type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo=hyperopt.tpe.suggest\n",
    "algo = hyperopt.rand.suggest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the model, you can track it in mlflow: [http://127.0.0.1:1234](http://127.0.0.1:1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timout_in_minutes = 24 * 60\n",
    "max_evals = 10\n",
    "\n",
    "## if java is installed (only recommended under linux/wsl)\n",
    "# import pyspark\n",
    "# spark_trails = hyperopt.SparkTrials(parallelism=4)\n",
    "# best_result = hyperopt.fmin(fn=partial(svm_objective,experiment_id=mlflow_exp.experiment_id),\n",
    "#                             space=search_space,\n",
    "#                             algo=algo,\n",
    "#                             max_evals=max_evals,\n",
    "#                             timeout=timout_in_minutes*60,\n",
    "#                             trials=spark_trails)\n",
    "# if java is not available\n",
    "best_result = hyperopt.fmin(\n",
    "    fn=partial(svm_objective, experiment_id=mlflow_exp.experiment_id),\n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=max_evals,\n",
    "    timeout=timout_in_minutes * 60,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyperopt.space_eval(search_space, best_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_this_run_eval = name_of_this_run\n",
    "\n",
    "destination_filepath = r\"./data/eis_datasets/\" + name_of_this_run_eval + \".parquet\"\n",
    "df_eval = pd.read_parquet(destination_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direct scaling on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval[key_lookup_df[\"EIS_Z_abs\"].to_list()] = arrhenius_correction(\n",
    "    df_eval[key_lookup_df[\"EIS_Z_abs\"].to_list()].values\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selection_eval = feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parameter_eval = output_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to arrays\n",
    "data_set_eval = dm.get_set(\n",
    "    df_eval,\n",
    "    output_parameter_eval,\n",
    "    feature_keys=feature_selection_eval,\n",
    "    validation_split=0.2,\n",
    "    output_intervals_for_test=[[150, 151]],\n",
    ")\n",
    "x_train_eval, y_train_eval = data_set_eval[\"train\"]\n",
    "x_validation_eval, y_validation_eval = data_set_eval[\"validation\"]\n",
    "x_test_eval, y_test_eval = data_set_eval[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open [http://127.0.0.1:1234](http://127.0.0.1:1234) to select a fitted model. If you click on it, you can extract the run ID. It could look like this: \"ad26474e8c324f84906c9fc501928cae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose a specific model\n",
    "# logged_model = 'ad26474e8c324f84906c9fc501928cae'\n",
    "# or just load the best model\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=[mlflow.get_experiment_by_name(experiment_name).experiment_id],\n",
    "    order_by=[\"metrics.max_mse\"],\n",
    "    max_results=1,\n",
    ")\n",
    "logged_model = runs[0].info.run_id\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "run_eval = mlflow.get_run(logged_model)\n",
    "loaded_model = mlflow.pyfunc.load_model(run_eval.info.artifact_uri + \"/model/\")\n",
    "\n",
    "train_mse_temp = evaluate_mse_svr(loaded_model, x_train_eval, y_train_eval)\n",
    "print(\"Train MSE: \" + str(train_mse_temp))\n",
    "validation_mse_temp = evaluate_mse_svr(\n",
    "    loaded_model, x_validation_eval, y_validation_eval\n",
    ")\n",
    "print(\"Validation MSE: \" + str(validation_mse_temp))\n",
    "if apply_test:\n",
    "    test_mse_temp = evaluate_mse_svr(loaded_model, x_test_eval, y_test_eval)\n",
    "    print(\"Test MSE: \" + str(test_mse_temp))\n",
    "\n",
    "print(\n",
    "    \"C: \"\n",
    "    + run_eval.data.params[\"svm__C\"]\n",
    "    + \", epsilon: \"\n",
    "    + run_eval.data.params[\"svm__epsilon\"]\n",
    "    + \", tol: \"\n",
    "    + run_eval.data.params[\"svm__tol\"]\n",
    "    + \", Gamma: \"\n",
    "    + run_eval.data.params[\"svm__gamma\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10 * cm, 10 * cm))\n",
    "\n",
    "cell_list = list(set(data_set_eval[\"df_train\"].index.get_level_values(0)))\n",
    "y_pred_train_eval = loaded_model.predict(x_train_eval)\n",
    "fig, ax = eisplot.cell_scatter(\n",
    "    data_set_eval, y_pred_train_eval, cell_names=cell_list, fig=fig, ax=ax\n",
    ")\n",
    "\n",
    "cell_list = list(set(data_set_eval[\"df_validation\"].index.get_level_values(0)))\n",
    "y_pred_validation_eval = loaded_model.predict(x_validation_eval)\n",
    "fig, ax = eisplot.cell_scatter(\n",
    "    data_set_eval,\n",
    "    y_pred_validation_eval,\n",
    "    cell_names=cell_list,\n",
    "    fig=fig,\n",
    "    ax=ax,\n",
    "    is_validation=True,\n",
    ")\n",
    "\n",
    "if apply_test:\n",
    "    cell_list = list(set(data_set_eval[\"df_test\"].index.get_level_values(0)))\n",
    "    y_pred_test_eval = loaded_model.predict(x_test_eval)\n",
    "    fig, ax = eisplot.cell_scatter(\n",
    "        data_set_eval,\n",
    "        y_pred_test_eval,\n",
    "        cell_names=cell_list,\n",
    "        fig=fig,\n",
    "        ax=ax,\n",
    "        is_test=True,\n",
    "    )\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0], [0], color=eisplot.rwth_colors.colors[(\"green\", 100)], label=\"ideal\"\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\".\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"2\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"orange\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"1\",\n",
    "        linestyle=\"\",\n",
    "        color=eisplot.rwth_colors.colors[(\"lavender\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "]\n",
    "if apply_test:\n",
    "    ax.legend(handles=legend_elements, loc=\"best\", scatterpoints=1, prop={\"size\": 8})\n",
    "else:\n",
    "    ax.legend(\n",
    "        handles=legend_elements[:-1], loc=\"best\", scatterpoints=1, prop={\"size\": 8}\n",
    "    )\n",
    "fig.subplots_adjust(bottom=0.14, left=0.19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this result is not the best, further analysis of the results is required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = mlflow_exp.experiment_id\n",
    "experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for exp in mlflow.search_experiments():\n",
    "    if exp.experiment_id == experiment_id:\n",
    "        experiment_tmp = mlflow.search_runs(experiment_ids=experiment_id)\n",
    "        experiment_list = pd.concat([experiment_list, experiment_tmp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_list = experiment_list.reset_index(drop=True)\n",
    "experiment_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not apply_test:\n",
    "    experiment_list[\"metrics.test_mse_temp\"] = np.NaN\n",
    "\n",
    "scatter_values = [\n",
    "    experiment_list[\"metrics.train_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.validation_mse_temp\"].values,\n",
    "    experiment_list[\"metrics.test_mse_temp\"].values,\n",
    "    experiment_list[\"params.svm__C\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.svm__epsilon\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.svm__tol\"].values.astype(np.float64),\n",
    "    experiment_list[\"params.svm__gamma\"].values.astype(np.float64),\n",
    "]\n",
    "df_experiment_svr = pd.DataFrame(\n",
    "    np.transpose(scatter_values),\n",
    "    columns=[\n",
    "        \"Train MSE in K\",\n",
    "        \"Validation MSE in K\",\n",
    "        \"Test MSE in K\",\n",
    "        \"C\",\n",
    "        \"Epsilon\",\n",
    "        \"Tolerance\",\n",
    "        \"Gamma\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## limit the error if necessary\n",
    "# df_experiment_svr[df_experiment_svr[\"Test MSE in K\"] > 10] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_experiment_svr = df_experiment_svr.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_experiment_svr.corr()\n",
    "corr.style.background_gradient(cmap=\"turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, axs = plt.subplots(7, 7, figsize=(15*cm, 15*cm),sharex=True)\n",
    "# axs = pd.plotting.scatter_matrix(df_experiment_svr, ax=axs, diagonal='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12 * cm, 12 * cm), sharex=True)\n",
    "\n",
    "variables = [\"C\", \"Epsilon\", \"Tolerance\", \"Gamma\"]\n",
    "\n",
    "for variable_idx, variable in enumerate(variables):\n",
    "    plot_column = np.floor(variable_idx / 2).astype(\"int\")\n",
    "    plot_row = variable_idx - 2 * plot_column\n",
    "\n",
    "    concave_hull_ratio = 0.25\n",
    "    if apply_test:\n",
    "        min_error = np.nanmin(\n",
    "            [\n",
    "                df_experiment_svr[\"Train MSE in K\"].values,\n",
    "                df_experiment_svr[\"Validation MSE in K\"].values,\n",
    "                df_experiment_svr[\"Test MSE in K\"].values,\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        min_error = np.nanmin(\n",
    "            [\n",
    "                df_experiment_svr[\"Train MSE in K\"].values,\n",
    "                df_experiment_svr[\"Validation MSE in K\"].values,\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (df_experiment_svr[\"Train MSE in K\"].values, df_experiment_svr[variable].values)\n",
    "    ).T\n",
    "    points = points[~np.isnan(points).any(axis=1)]\n",
    "    # axs[plot_column,plot_row].scatter(df_experiment_svr[\"Train MSE in K\"].values,df_experiment_svr[variable].values,c=eisplot.rwth_colors.colors[('blue', 100)], alpha=0.1,marker='.')\n",
    "    points_hull = np.exp(\n",
    "        np.array(\n",
    "            shapely.concave_hull(\n",
    "                shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "            ).exterior.coords\n",
    "        )\n",
    "    )\n",
    "    axs[plot_column, plot_row].fill(\n",
    "        points_hull[:, 0],\n",
    "        points_hull[:, 1],\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "\n",
    "    points = np.vstack(\n",
    "        (\n",
    "            df_experiment_svr[\"Validation MSE in K\"].values,\n",
    "            df_experiment_svr[variable].values,\n",
    "        )\n",
    "    ).T\n",
    "    points = points[~np.isnan(points).any(axis=1)]\n",
    "    # axs[plot_column,plot_row].scatter(df_experiment_svr[\"Validation MSE in K\"].values,df_experiment_svr[variable].values,c=eisplot.rwth_colors.colors[('orange', 100)], alpha=0.1,marker='.')\n",
    "    points_hull = np.exp(\n",
    "        np.array(\n",
    "            shapely.concave_hull(\n",
    "                shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "            ).exterior.coords\n",
    "        )\n",
    "    )\n",
    "    axs[plot_column, plot_row].fill(\n",
    "        points_hull[:, 0],\n",
    "        points_hull[:, 1],\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    if apply_test:\n",
    "        points = np.vstack(\n",
    "            (\n",
    "                df_experiment_svr[\"Test MSE in K\"].values,\n",
    "                df_experiment_svr[variable].values,\n",
    "            )\n",
    "        ).T\n",
    "        points = points[~np.isnan(points).any(axis=1)]\n",
    "        # axs[plot_column,plot_row].scatter(df_experiment_svr[\"Test MSE in K\"].values,df_experiment_svr[variable].values,c=eisplot.rwth_colors.colors[('lavender', 100)], alpha=0.1,marker='.')\n",
    "        points_hull = np.exp(\n",
    "            np.array(\n",
    "                shapely.concave_hull(\n",
    "                    shapely.MultiPoint(np.log(points)), ratio=concave_hull_ratio\n",
    "                ).exterior.coords\n",
    "            )\n",
    "        )\n",
    "        axs[plot_column, plot_row].fill(\n",
    "            points_hull[:, 0],\n",
    "            points_hull[:, 1],\n",
    "            color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "    axs[plot_column, plot_row].set_ylabel(variable)\n",
    "    axs[plot_column, plot_row].set_yscale(\"log\")\n",
    "    axs[plot_column, plot_row].set_xscale(\"log\")\n",
    "    axs[plot_column, plot_row].grid()\n",
    "    axs[plot_column, plot_row].set_xlim([min_error * 0.8, 200])\n",
    "\n",
    "\n",
    "legend_elements = [\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"petrol\", 100)],\n",
    "        label=\"train\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"turqoise\", 100)],\n",
    "        label=\"validation\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\"-\",\n",
    "        color=eisplot.rwth_colors.colors[(\"blue\", 100)],\n",
    "        label=\"test\",\n",
    "        alpha=0.5,\n",
    "    ),\n",
    "    mpl.lines.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"\",\n",
    "        linestyle=\":\",\n",
    "        color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    "        label=\"selected value\",\n",
    "        alpha=1.0,\n",
    "    ),\n",
    "]\n",
    "if not apply_test:\n",
    "    legend_elements.pop(2)\n",
    "fig.legend(\n",
    "    handles=legend_elements,\n",
    "    loc=\"upper center\",\n",
    "    scatterpoints=1,\n",
    "    prop={\"size\": 8},\n",
    "    ncol=4,\n",
    ")\n",
    "\n",
    "\n",
    "axs[1, 0].set_xlabel(\"MSE in K\", size=8)\n",
    "axs[1, 1].set_xlabel(\"MSE in K\", size=8)\n",
    "fig.tight_layout()\n",
    "\n",
    "x_values = np.array(axs[0, 0].get_xlim()) * 0.95\n",
    "\n",
    "axs[0, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"svm__C\"]), float(run_eval.data.params[\"svm__C\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[0, 1].plot(\n",
    "    x_values,\n",
    "    [\n",
    "        float(run_eval.data.params[\"svm__epsilon\"]),\n",
    "        float(run_eval.data.params[\"svm__epsilon\"]),\n",
    "    ],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 0].plot(\n",
    "    x_values,\n",
    "    [float(run_eval.data.params[\"svm__tol\"]), float(run_eval.data.params[\"svm__tol\"])],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "axs[1, 1].plot(\n",
    "    x_values,\n",
    "    [\n",
    "        float(run_eval.data.params[\"svm__gamma\"]),\n",
    "        float(run_eval.data.params[\"svm__gamma\"]),\n",
    "    ],\n",
    "    linestyle=\":\",\n",
    "    color=eisplot.rwth_colors.colors[(\"darkred\", 100)],\n",
    ")\n",
    "\n",
    "fig.subplots_adjust(top=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_name = (\n",
    "    name_of_the_feature\n",
    "    + \"\"\n",
    "    + \"_ExpID_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \"_RunID_\"\n",
    "    + logged_model\n",
    ")\n",
    "plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".pdf\")\n",
    "plt.savefig(r\"./figures/\" + name_of_this_run + \"_\" + plot_name + \".png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_filepath = (\n",
    "    r\"./mlruns/\"\n",
    "    + name_of_this_run\n",
    "    + \"_ExpID_\"\n",
    "    + mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "    + \".parquet\"\n",
    ")\n",
    "experiment_list.to_parquet(destination_filepath, compression=\"gzip\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "05d28ba11f89102f70830e5c492d80edd1401f4565ce2c5eed021df0239ed7ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
